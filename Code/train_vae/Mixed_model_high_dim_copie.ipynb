{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from get_models import Progress_Bar, Encoder, Decoder, CovarianceMatrix, thermometer_encode_df\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2\n",
    "from torchmin import minimize\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframes: test_scores has high dimensional test score data of hfsme tests\n",
    "test_scores_df = pd.read_csv(os.getcwd()+'/test_scores.csv')\n",
    "\n",
    "#test_scores_df_encoded is a thermometer encoding of test_scores_df for the encoder network\n",
    "test_scores_df_encoded = thermometer_encode_df(test_scores_df, test_scores_df.columns[1:])\n",
    "\n",
    "#time_df contains data that changes with time, e.g.: age or time since medication switch\n",
    "time_df = pd.read_csv(os.getcwd()+'/time_df.csv')\n",
    "time_df['intercept'] = np.ones(time_df.shape[0])\n",
    "\n",
    "#baseline_df contains features that characterizes patients at baseline\n",
    "baseline_df = pd.read_csv(os.getcwd()+'/baseline_df.csv')\n",
    "\n",
    "# 'sex' has no influence:\n",
    "baseline_df['sex'] = np.random.randint(2, size=baseline_df.shape[0])\n",
    "\n",
    "df_effects = pd.merge(baseline_df, time_df, on='patient_id', how='inner')\n",
    "\n",
    "fixed_effects_keys = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never', 'sex']\n",
    "random_effects_keys = ['intercept', 'since_medication', 'since_switch']\n",
    "\n",
    "p = len(fixed_effects_keys)\n",
    "q = len(random_effects_keys)\n",
    "\n",
    "#vae latent dimension\n",
    "latent_dim = 2\n",
    "\n",
    "def get_ind(id, df):\n",
    "    return np.where(df['patient_id'] == id)[0]\n",
    "\n",
    "def get_design_matrix(df_effects, fixed_effects_keys, random_effects_keys, r=1, include_interaction=False):\n",
    "    patient_id = df_effects['patient_id'].unique()\n",
    "\n",
    "    X_list = [torch.from_numpy(np.array(df_effects.loc[get_ind(id, df_effects), fixed_effects_keys])).to(torch.float32) for id in patient_id]\n",
    "\n",
    "    if include_interaction==True:\n",
    "        for key in random_effects_keys[1:]:\n",
    "            X_list = [torch.cat((X_i, X_i[:,1:] * torch.from_numpy(np.array(df_effects.loc[get_ind(patient_id[j], df_effects), key])).unsqueeze(-1)\n",
    "                                ), -1).to(torch.float32) for j,X_i in enumerate(X_list)]\n",
    "\n",
    "    X_list = [torch.cat((torch.from_numpy(np.array(df_effects.loc[get_ind(patient_id[j], df_effects), 'age'])).unsqueeze(-1), X_i), -1).to(torch.float32) for j,X_i in enumerate(X_list)]\n",
    "\n",
    "\n",
    "    Z_list = [torch.from_numpy(np.array(df_effects.loc[get_ind(id, df_effects), random_effects_keys])).to(torch.float32) for id in patient_id]\n",
    "    Z_list = [torch.block_diag(*[i for j in range(r)]) for i in Z_list]   \n",
    "    X_list = [torch.block_diag(*[i for j in range(r)]) for i in X_list]\n",
    "    return X_list, Z_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim =  1\n",
    "X_list, Z_list = get_design_matrix(df_effects, fixed_effects_keys, random_effects_keys, r=latent_dim, include_interaction=False)\n",
    "pat_ind = np.cumsum([0]+[int(len(X_i)/latent_dim) for X_i in X_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Encoder and Decoder Models and the Mixed Model Parameters. mode='diagonal': Diagonal Covariance Matrix, mode='full': Full Covariance Matrix,\n",
    "def initialize(latent_dim, mode='diagonal'):\n",
    "    encoder = Encoder(\n",
    "        input_dim=np.shape(test_scores_df_encoded)[-1],\n",
    "        hidden_dims=[150], \n",
    "        output_dim=latent_dim, \n",
    "        act=torch.nn.Tanh())\n",
    "\n",
    "    decoder = Decoder(\n",
    "        item_positions=np.concatenate([[i]*a for i,a in enumerate(np.array(test_scores_df[test_scores_df.columns[1:]].max(0)).astype(np.int32))]),                            \n",
    "        input_dim=latent_dim,\n",
    "        hidden_dims=[150], \n",
    "        act=torch.nn.Tanh())\n",
    "\n",
    "    var_param = CovarianceMatrix(q*latent_dim, mode=mode)    \n",
    "    return encoder, decoder, var_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = torch.from_numpy(np.array(baseline_df['patient_id']))\n",
    "num_patients = len(patients)\n",
    "\n",
    "#Train the VAE model:  Weighting of the loss function\n",
    "# alpha: kl-divergence weight;  \n",
    "# delta: MSE distance between encoder prediction and decoder; \n",
    "# gamma: decoder reconstruction loss\n",
    "# eta: mixed model loss\n",
    "\n",
    "# batch_size should be greater than 50\n",
    "def train_vae(epochs, batch_size, X_list, Z_list, encoder, decoder, var_param, optimizer_vae, alpha=1, gamma=1, delta=0, eta=0):\n",
    "    steps = int(num_patients / batch_size)\n",
    "    rng = np.random.default_rng(1234)\n",
    "    prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
    "    progBar = Progress_Bar(epochs, steps, ['nELBO', 'KL', 'nML', 'Rec Loss', 'Residuals', 'Item Error'])\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        shuffle = rng.permutation(num_patients)\n",
    "        \n",
    "        for step in range(steps):\n",
    "            #draw minibatch\n",
    "            pat_batch = patients[shuffle[step*batch_size:(step+1)*batch_size]]\n",
    "            pat_ind_batch = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in pat_batch]\n",
    "            \n",
    "            ind_batch = []\n",
    "            add = 0\n",
    "            for ind in range(len(pat_ind_batch)):\n",
    "                len_i = len(pat_ind_batch[ind])\n",
    "                ind_batch += [torch.arange(add, add + len_i)]\n",
    "                add += len_i\n",
    "\n",
    "            Z_list_batch = [Z_list[pat] for pat in pat_batch]\n",
    "            X_list_batch = [X_list[pat] for pat in pat_batch]\n",
    "            \n",
    "            # warum nicht torch.cat statt concatenate\n",
    "            test_data = torch.concatenate([torch.from_numpy(np.array(test_scores_df_encoded.loc[ind])).to(torch.float32) for ind in pat_ind_batch])\n",
    "            test_data_orig = torch.concatenate([torch.from_numpy(np.array(test_scores_df[test_scores_df.columns[1:]].loc[ind])).to(torch.int32) for ind in pat_ind_batch])\n",
    "            \n",
    "            optimizer_vae.zero_grad(set_to_none=True)\n",
    "            #encode test scores\n",
    "            mu, log_sig = encoder.encode(test_data)\n",
    "\n",
    "            #reparametrization trick to get latent variables\n",
    "            eps = prior.sample(torch.Size([log_sig.size(dim=0)]))\n",
    "            z = mu + log_sig.exp() * eps\n",
    "            \n",
    "            #kl divergence\n",
    "            kl = torch.mean(0.5 * torch.sum(mu.square() + torch.exp(2.0 * log_sig) - 1.0 - (2.0 * log_sig), dim=1))\n",
    "\n",
    "            # get the response variable list (latent z)\n",
    "            z_list = [z[ind].flatten().to(torch.float32) for ind in ind_batch]\n",
    "\n",
    "            #Mixed model loglikelihood loss. Notation follows https://www.sfu.ca/sasdoc/sashtml/stat/chap41/sect23.htm\n",
    "            Phi, sigma = var_param()\n",
    "            N = sum([len(Z_i) for Z_i in Z_list_batch])\n",
    "\n",
    "            V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list_batch]\n",
    "            V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "            \n",
    "            Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list_batch, V_inv_list)]).sum(dim=0)\n",
    "            Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list_batch, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "            #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
    "            if torch.abs(torch.det(Xt_V_inv_X)) > 1e-6:\n",
    "                EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "                EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_batch, Z_list_batch, V_inv_list, z_list)]\n",
    "\n",
    "                residual_list = [y_i - X_i @ EBLUE for y_i, X_i in zip(z_list, X_list_batch)]\n",
    "                #Mixed model prediction\n",
    "                z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_batch, Z_list_batch, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "\n",
    "                log_det_V = torch.stack([V_i.det().clamp(min=1e-12).log() for V_i in V_list]).sum()\n",
    "                const = torch.log(torch.tensor(2.0 * torch.pi))\n",
    "                rt_V_inv_r = torch.stack([r_i.t() @ V_i_inv @ r_i for r_i, V_i_inv in zip(residual_list, V_inv_list)]).sum()\n",
    "\n",
    "                #negative mixed models likelihood\n",
    "                nML = 0.5 * (log_det_V + rt_V_inv_r + N * const) / N\n",
    "                \n",
    "                #distance between encoder latent variables and mixed model prediction\n",
    "                residuals = ((z_pred - z) ** 2).sum(1).mean()\n",
    "\n",
    "                #reconstruction loss\n",
    "                rec_loss, probs = decoder(z, test_data_orig)\n",
    "                nelbo = alpha * kl + delta * residuals + gamma * rec_loss + eta * nML\n",
    "                \n",
    "                nelbo.backward()\n",
    "                optimizer_vae.step()\n",
    "\n",
    "                data_pred = torch.stack([torch.argmax(pred, dim=-1) for pred in probs]) \n",
    "                # total test item prediction error  \n",
    "                item_error = np.mean(np.sum(np.abs(data_pred.detach().numpy() - test_data_orig.T.numpy()), axis=0))\n",
    "\n",
    "                progBar.update({\n",
    "                    'nELBO': nelbo.item(), \n",
    "                    'KL': alpha * kl.item(), \n",
    "                    'nML': eta * nML.item(),\n",
    "                    'Rec Loss': gamma * rec_loss.item(), \n",
    "                    'Residuals': delta * residuals.item(),\n",
    "                    'Item Error': item_error,\n",
    "                    }) \n",
    "            \n",
    "#train_vae(300, 60,X_list, Z_list, encoder, decoder, var_param, optimizer_vae, alpha=1, gamma=1, delta=1, eta=1)  \n",
    "# get the model prediction:\n",
    "def eval_vae(X_list, Z_list, var_param, encoder):\n",
    "    with torch.no_grad():\n",
    "        pat_ind_batch = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in patients]\n",
    "        prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
    "\n",
    "        test_data = torch.concatenate([torch.from_numpy(np.array(test_scores_df_encoded.loc[ind])).to(torch.float32) for ind in pat_ind_batch])\n",
    "\n",
    "        mu, log_sig = encoder.encode(test_data)\n",
    "\n",
    "        eps = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
    "        z = mu + log_sig.exp() * eps # latent data\n",
    "\n",
    "        z_list = [z[ind].flatten().to(torch.float32) for ind in pat_ind_batch]\n",
    "\n",
    "        Phi, sigma = var_param()\n",
    "        N = sum([len(Z_i) for Z_i in Z_list])\n",
    "\n",
    "        V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list]\n",
    "        V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "        \n",
    "        Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list, V_inv_list)]).sum(dim=0)\n",
    "        Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "        EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "        EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list, Z_list, V_inv_list, z_list)]\n",
    "\n",
    "        residual_list = [y_i - X_i @ EBLUE for y_i, X_i in zip(z_list, X_list)]\n",
    "        z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list, Z_list, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "\n",
    "        log_det_V = torch.stack([V_i.det().clamp(min=1e-12).log() for V_i in V_list]).sum()\n",
    "        const = torch.log(torch.tensor(2.0 * torch.pi))\n",
    "        rt_V_inv_r = torch.stack([r_i.t() @ V_i_inv @ r_i for r_i, V_i_inv in zip(residual_list, V_inv_list)]).sum()\n",
    "\n",
    "        nML = 0.5 * (log_det_V + rt_V_inv_r + N * const) \n",
    "        return mu, z, z_pred, nML\n",
    "    \n",
    "# mu, z, z_pred, nML = eval_vae(X_list, Z_list, var_param, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_ratio(L_full, L_red):\n",
    "    return 2 * (L_full - L_red)\n",
    "\n",
    "# returns a block diagonal matrix of a list of matrices\n",
    "def block_diag_list(arrs_list):\n",
    "    shape = torch.sum(torch.tensor([a.shape for a in arrs_list], dtype=torch.int32), dim=0)\n",
    "    dtype = arrs_list[0].dtype\n",
    "    device = arrs_list[0].device\n",
    "\n",
    "    out = torch.zeros(*shape.tolist(), dtype=dtype, device=device)\n",
    "\n",
    "    r, c = 0, 0\n",
    "    for a in arrs_list:\n",
    "        rows, cols = a.shape\n",
    "        out[r:r + rows, c:c + cols] = a\n",
    "        r += rows\n",
    "        c += cols\n",
    "    return out\n",
    "\n",
    "\n",
    "def calc_mmloss(var_param, X_list, Z_list, y_list, calc_reml=False):\n",
    "    Phi, sigma = var_param()\n",
    "    N = sum([len(Z_i) for Z_i in Z_list])\n",
    "\n",
    "    V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list]\n",
    "    V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "\n",
    "    Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list, V_inv_list)]).sum(dim=0)\n",
    "    Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list, V_inv_list, y_list)]).sum(dim=0)\n",
    "\n",
    "    N = sum([len(Z_i) for Z_i in Z_list])\n",
    "\n",
    "    EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "    EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list, Z_list, V_inv_list, y_list)]\n",
    "\n",
    "    residual_list = [y_i - X_i @ EBLUE for y_i, X_i in zip(y_list, X_list)]\n",
    "\n",
    "    log_det_V = torch.stack([V_i.det().clamp(min=1e-12).log() for V_i in V_list]).sum()\n",
    "    const = torch.log(torch.tensor(2.0 * torch.pi))\n",
    "    rt_V_inv_r = torch.stack([r_i.t() @ V_i_inv @ r_i for r_i, V_i_inv in zip(residual_list, V_inv_list)]).sum()\n",
    "\n",
    "    # #negative mixed models likelihood\n",
    "    nML = 0.5 * (log_det_V + rt_V_inv_r + N * const) / N\n",
    "\n",
    "    if calc_reml:\n",
    "        p = Xt_V_inv_X.size(0)\n",
    "        reml = nML + 0.5 * p * const / N\n",
    "        return nML, reml\n",
    "\n",
    "    return nML\n",
    "\n",
    "def train_mixed_model(var_param, X_list, Z_list, y_list, learning_rate=0.01, epochs=100):\n",
    "    optimizer = torch.optim.Adam(var_param.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        nML = calc_mmloss(var_param, X_list, Z_list, y_list)\n",
    "        nML.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    return var_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mProgress\u001b[00m: 77.0%\u001b[96m - \u001b[00m\u001b[95mETA\u001b[00m: 0:01:43\u001b[96m - \u001b[00m\u001b[95mEpoch\u001b[00m: 154\u001b[96m - \u001b[00m\u001b[95mIteration\u001b[00m: 616\u001b[96m - \u001b[00m\u001b[95mms/Iteration\u001b[00m: 559.9\u001b[96m - \u001b[00m\u001b[33mnELBO\u001b[00m: 7.8872 (\u001b[92m+0.068\u001b[00m)\u001b[96m - \u001b[00m\u001b[33mKL\u001b[00m: 2.3849 (\u001b[92m+0.050\u001b[00m)\u001b[96m - \u001b[00m\u001b[33mnML\u001b[00m: 0.0000 (---)\u001b[96m - \u001b[00m\u001b[33mRec Loss\u001b[00m: 5.5023 (\u001b[92m+0.018\u001b[00m)\u001b[96m - \u001b[00m\u001b[33mResiduals\u001b[00m: 0.0000 (---)\u001b[96m - \u001b[00m\u001b[33mItem Error\u001b[00m: 2.8358 (\u001b[92m+0.039\u001b[00m).           "
     ]
    }
   ],
   "source": [
    "\n",
    "encoder, decoder, var_param = initialize(latent_dim, mode='diagonal')\n",
    "optimizer_vae = torch.optim.Adam([\n",
    "    #{'params': var_param.parameters(), 'lr': 0.1},  \n",
    "    {'params': encoder.parameters(), 'lr': 0.01},  \n",
    "    {'params': decoder.parameters(), 'lr': 0.01},  \n",
    "]) \n",
    "train_vae(200,60, X_list, Z_list, encoder, decoder, var_param, optimizer_vae, delta=0, eta=0)\n",
    "latent_rep = eval_vae(X_list, Z_list, var_param, encoder)[1].clone().detach().float()\n",
    "latent_data = latent_rep.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mProgress\u001b[00m: 77.4%\u001b[96m - \u001b[00m\u001b[95mETA\u001b[00m: 0:01:50\u001b[96m - \u001b[00m\u001b[95mEpoch\u001b[00m: 155\u001b[96m - \u001b[00m\u001b[95mIteration\u001b[00m: 619\u001b[96m - \u001b[00m\u001b[95mms/Iteration\u001b[00m: 611.2\u001b[96m - \u001b[00m\u001b[33mnELBO\u001b[00m: 7.8047 (\u001b[91m-0.133\u001b[00m)\u001b[96m - \u001b[00m\u001b[33mKL\u001b[00m: 2.3814 (\u001b[92m+0.042\u001b[00m)\u001b[96m - \u001b[00m\u001b[33mnML\u001b[00m: 0.0000 (---)\u001b[96m - \u001b[00m\u001b[33mRec Loss\u001b[00m: 5.4233 (\u001b[91m-0.175\u001b[00m)\u001b[96m - \u001b[00m\u001b[33mResiduals\u001b[00m: 0.0000 (---)\u001b[96m - \u001b[00m\u001b[33mItem Error\u001b[00m: 2.7913 (\u001b[91m-0.101\u001b[00m).           "
     ]
    }
   ],
   "source": [
    "num_simulations = 10\n",
    "\n",
    "fixed_effects_keys_full = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never', 'sex']\n",
    "random_effects_keys_full = ['intercept', 'since_medication', 'since_switch']\n",
    "# reduced model without fixed effect 'sex' \n",
    "fixed_effects_keys_red = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never']\n",
    "random_effects_keys_red = ['intercept', 'since_medication', 'since_switch']\n",
    "\n",
    "X_list_full, Z_list_full = get_design_matrix(df_effects, fixed_effects_keys_full, random_effects_keys_full, r=latent_dim, include_interaction=False)\n",
    "X_list_red, Z_list_red = get_design_matrix(df_effects, fixed_effects_keys_red, random_effects_keys_red, r=latent_dim, include_interaction=False)\n",
    "# a, z, c, d= eval_vae(X_list, Z_list, var_param, encoder)\n",
    "pat_ind_batch = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in patients]\n",
    "# y_list =  [z[ind].flatten().to(torch.float32) for ind in pat_ind_batch]\n",
    "lrt_results = []\n",
    "for _ in range(num_simulations):\n",
    "    encoder, decoder, var_param = initialize(latent_dim, mode='diagonal')\n",
    "    optimizer_vae = torch.optim.Adam([\n",
    "    #{'params': var_param.parameters(), 'lr': 0.1},  \n",
    "    {'params': encoder.parameters(), 'lr': 0.01},  \n",
    "    {'params': decoder.parameters(), 'lr': 0.01},  \n",
    "    ]) \n",
    "    train_vae(200,60, X_list, Z_list, encoder, decoder, var_param, optimizer_vae, delta=0, eta=0)\n",
    "    a, z, c, d= eval_vae(X_list, Z_list, var_param, encoder)\n",
    "    y_list =  [z[ind].flatten().to(torch.float32) for ind in pat_ind_batch]\n",
    "    a, b, var_param_full = initialize(latent_dim)\n",
    "    a, b, var_param_red = initialize(latent_dim)\n",
    "    var_param_full = train_mixed_model(var_param_full, X_list_full, Z_list_full, y_list, learning_rate=0.01, epochs=100)\n",
    "    var_param_red = train_mixed_model(var_param_red, X_list_red, Z_list_red, y_list, learning_rate=0.01, epochs=100)\n",
    "    L_full = calc_mmloss(var_param_full, X_list_full, Z_list_full, y_list)\n",
    "    L_red = calc_mmloss(var_param_red, X_list_red, Z_list_red, y_list)\n",
    "    lrt_results.append(likelihood_ratio(L_full.item(), L_red.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m y \u001b[38;5;241m=\u001b[39m y_list \n\u001b[0;32m     21\u001b[0m X_tilde_list \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mcat((X_i, torch\u001b[38;5;241m.\u001b[39mzeros((n_rand_eff, n_fixed_eff)))) \u001b[38;5;28;01mfor\u001b[39;00m X_i \u001b[38;5;129;01min\u001b[39;00m X_list_full] \u001b[38;5;66;03m# Defining list of X tilde (eq. 2.7 p. 63)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m y_e \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mcat((y[get_ind(pat,df_effects)], torch\u001b[38;5;241m.\u001b[39mzeros(n_rand_eff)))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m pat \u001b[38;5;129;01min\u001b[39;00m df_effects[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()]) \u001b[38;5;66;03m# Augmented response vector y_e (eq. 2.11 p. 65)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m X_tilde_list_r \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mcat((X_i, torch\u001b[38;5;241m.\u001b[39mzeros((n_rand_eff_r, n_fixed_eff_r)))) \u001b[38;5;28;01mfor\u001b[39;00m X_i \u001b[38;5;129;01min\u001b[39;00m X_list_red] \u001b[38;5;66;03m# Defining list of X tilde (eq. 2.7 p. 63)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_simulations):\n",
      "Cell \u001b[1;32mIn[101], line 22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m y \u001b[38;5;241m=\u001b[39m y_list \n\u001b[0;32m     21\u001b[0m X_tilde_list \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mcat((X_i, torch\u001b[38;5;241m.\u001b[39mzeros((n_rand_eff, n_fixed_eff)))) \u001b[38;5;28;01mfor\u001b[39;00m X_i \u001b[38;5;129;01min\u001b[39;00m X_list_full] \u001b[38;5;66;03m# Defining list of X tilde (eq. 2.7 p. 63)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m y_e \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mcat((\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_ind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_effects\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m, torch\u001b[38;5;241m.\u001b[39mzeros(n_rand_eff)))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m pat \u001b[38;5;129;01min\u001b[39;00m df_effects[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()]) \u001b[38;5;66;03m# Augmented response vector y_e (eq. 2.11 p. 65)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m X_tilde_list_r \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mcat((X_i, torch\u001b[38;5;241m.\u001b[39mzeros((n_rand_eff_r, n_fixed_eff_r)))) \u001b[38;5;28;01mfor\u001b[39;00m X_i \u001b[38;5;129;01min\u001b[39;00m X_list_red] \u001b[38;5;66;03m# Defining list of X tilde (eq. 2.7 p. 63)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_simulations):\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "num_simulations = 10\n",
    "\n",
    "fixed_effects_keys_full = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never', 'sex']\n",
    "random_effects_keys_full = ['intercept', 'since_medication', 'since_switch']\n",
    "# reduced model without fixed effect 'sex' \n",
    "fixed_effects_keys_red = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never']\n",
    "random_effects_keys_red = ['intercept', 'since_medication', 'since_switch']\n",
    "\n",
    "X_list_full, Z_list_full = get_design_matrix(df_effects, fixed_effects_keys_full, random_effects_keys_full, r=latent_dim, include_interaction=False)\n",
    "X_list_red, Z_list_red = get_design_matrix(df_effects, fixed_effects_keys_red, random_effects_keys_red, r=latent_dim, include_interaction=False)\n",
    "\n",
    "n_fixed_eff = len(fixed_effects_keys) + 1\n",
    "n_rand_eff = len(random_effects_keys) \n",
    "n_fixed_eff_r = len(fixed_effects_keys_red) + 1\n",
    "n_rand_eff_r = len(random_effects_keys_red) \n",
    "softplus = torch.nn.Softplus()\n",
    "lrt_results = []\n",
    "\n",
    "N = len(latent_data)\n",
    "y = y_list \n",
    "X_tilde_list = [torch.cat((X_i, torch.zeros((n_rand_eff, n_fixed_eff)))) for X_i in X_list_full] # Defining list of X tilde (eq. 2.7 p. 63)\n",
    "y_e = torch.cat([torch.cat((y[get_ind(pat,df_effects)], torch.zeros(n_rand_eff))).unsqueeze(-1) for pat in df_effects['patient_id'].unique()]) # Augmented response vector y_e (eq. 2.11 p. 65)\n",
    "X_tilde_list_r = [torch.cat((X_i, torch.zeros((n_rand_eff_r, n_fixed_eff_r)))) for X_i in X_list_red] # Defining list of X tilde (eq. 2.7 p. 63)\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "    D_param = torch.randn(n_rand_eff, requires_grad=True) # Learnable parameter for diagonal covariance matrix\n",
    "    D_param_r = torch.randn(n_rand_eff_r, requires_grad=True) # Learnable parameter for diagonal covariance matrix\n",
    "    def calculate_likelihood_full(D_param): \n",
    "        # Ensure that the diagonal covariance matrix has only positive values\n",
    "        Delta = torch.diag(softplus(D_param))\n",
    "        det_Delta = torch.det(Delta)  \n",
    "\n",
    "        # Defining list of Z tilde (eq. 2.7 p. 63)\n",
    "        Z_tilde_list = [torch.cat((Z_i, Delta)) for Z_i in Z_list_full]\n",
    "        # Matrix X_e (eq. 2.11 p. 65)\n",
    "        X_e = torch.cat((block_diag_list(Z_tilde_list), torch.cat(X_tilde_list)), -1)\n",
    "        # Calculate MLE estimates of random and fixed effects with current set of covariance Parameters (eq. 2.11 p. 65)\n",
    "        pred = torch.inverse((X_e.t() @ X_e)) @ X_e.t() @ y_e\n",
    "        # Calculate MLE estimates of the noise sigma with current set of covariance Parameters (eq. 2.12 p. 65)\n",
    "        pred_sigma = torch.sum((y_e - X_e @ pred) ** 2) / N\n",
    "\n",
    "        # Calculate the logarithm of the likelihood function in (eq. 2.13 p. 65)\n",
    "        likelihood = -N/2 * (1 + torch.log(torch.tensor(2 * torch.pi)) + torch.log(pred_sigma))\n",
    "        likelihood += torch.log(torch.stack([det_Delta/torch.det(Z_i_tilde.t() @ Z_i_tilde).sqrt() for Z_i_tilde in Z_tilde_list])).sum()\n",
    "        return - likelihood\n",
    "    \n",
    "    result_full = minimize(calculate_likelihood_full, D_param, method='bfgs', max_iter=6)\n",
    "    Lmax = result_full.fun\n",
    "    def calculate_likelihood_reduced(D_param_r):\n",
    "        # Ensure that the diagonal covariance matrix has only positive values\n",
    "        Delta_r = torch.diag(softplus(D_param_r))\n",
    "        det_Delta_r = torch.det(Delta_r)  \n",
    "\n",
    "        # Defining list of Z tilde (eq. 2.7 p. 63)\n",
    "        Z_tilde_list_r = [torch.cat((Z_i, Delta_r)) for Z_i in Z_list_red]\n",
    "        # Matrix X_e (eq. 2.11 p. 65)\n",
    "        X_e_r = torch.cat((block_diag_list(Z_tilde_list_r), torch.cat(X_tilde_list_r)), -1)\n",
    "\n",
    "        # Calculate MLE estimates of random and fixed effects with current set of covariance Parameters (eq. 2.11 p. 65)\n",
    "        pred_r = torch.inverse((X_e_r.t() @ X_e_r)) @ X_e_r.t() @ y_e\n",
    "        # Calculate MLE estimates of the noise sigma with current set of covariance Parameters (eq. 2.12 p. 65)\n",
    "        pred_sigma_r = torch.sum((y_e - X_e_r @ pred_r) ** 2) / N\n",
    "\n",
    "        # Calculate the logarithm of the likelihood function in (eq. 2.13 p. 65)\n",
    "        likelihood = -N/2 * (1 + torch.log(torch.tensor(2 * torch.pi)) + torch.log(pred_sigma_r))\n",
    "        likelihood += torch.log(torch.stack([det_Delta_r/torch.det(Z_i_tilde_r.t() @ Z_i_tilde_r).sqrt() for Z_i_tilde_r in Z_tilde_list_r])).sum()\n",
    "        return - likelihood\n",
    "    result_reduced = minimize(calculate_likelihood_reduced, D_param_r, method='bfgs', max_iter=6)\n",
    "    Lmin = result_reduced.fun\n",
    "\n",
    "    lrt_results.append(likelihood_ratio(Lmax,Lmin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the histogr<am of the LRT-statistic\n",
    "plt.hist(lrt_results, bins=50, density=True, alpha=0.6, color='g', label='Histogramm für 35 Simulationen')\n",
    "\n",
    "#x = np.linspace(-8000, 8000, 100)\n",
    "#plt.plot(x, chi2.pdf(x + 500, df=1), 'r-', lw=2, label='Chi-Quadrat-Verteilung (df=1)')\n",
    "\n",
    "# Beschriftungen hinzufügen\n",
    "plt.title('Histogramm der Likelihood-Ratio-Teststatistiken')\n",
    "plt.xlabel('Teststatistik')\n",
    "plt.ylabel('Häufigkeit')\n",
    "plt.legend()\n",
    "\n",
    "# Histogramm anzeigen\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
