{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATING THE DATA \n",
    "\n",
    "# PARAMETERS\n",
    "num_patients = 200 # number of patients\n",
    "patient_affected_prob = 0.6 # probability if patient is affected\n",
    "mean_test_score = 40 # fixed intercept\n",
    "\n",
    "noise_var = 0.1  \n",
    "var_time_effect = 1.0\n",
    "var_intercept = 1.0  # intercept steht für Ausgangsniveau\n",
    "var_slope = 0.1 # slope steht für effektstärke / steigung\n",
    "\n",
    "b_1 = -4.0 # effect of affected family\n",
    "b_2 = 0.0 # effect of sex \n",
    "b_3 = 0.2 # effect of age\n",
    "\n",
    "# calculating data for num_patients patients \n",
    "def simulate_data(num_patients):\n",
    "    # Generate data\n",
    "    data = []\n",
    "    data_we = []\n",
    "\n",
    "    # simuliere einen Datensatz eines Krankheitsverlauf mit infizierten und gesunden Patienten def simulate_dataset(num_patients):\n",
    "    for patient_id in range(num_patients):\n",
    "        # Randomly determine if family is affected\n",
    "        patient_affected = np.random.choice([0, 1], p=[1-patient_affected_prob, patient_affected_prob])\n",
    "    \n",
    "        # Randomly determine sex\n",
    "        sex = np.random.choice([0, 1], p=[1-0.5,0.5]) # 50/50 male or women \n",
    "\n",
    "        # Randomly determine age\n",
    "        age = np.random.normal(40,10) # mean_age=40, age_std=10\n",
    "    \n",
    "        # Randomly generate time points\n",
    "        num_time_points = np.random.choice([4,5,6,7,8,9,10])\n",
    "        time_points = np.sort(np.random.uniform(0, 10, num_time_points))\n",
    "    \n",
    "        # Generate random effects\n",
    "        random_intercept = np.random.normal(0.0,np.sqrt(var_intercept))\n",
    "        random_slope = np.random.normal(0.0, var_slope)\n",
    "        time_effects = np.random.normal(0.0, np.sqrt(var_time_effect))\n",
    "    \n",
    "        for j,t in enumerate(time_points):\n",
    "            # Generate noise\n",
    "            noise = np.random.normal(0.0, np.sqrt(noise_var))\n",
    "        \n",
    "            # Simulate test score\n",
    "            test_score = mean_test_score + random_intercept + b_1 * patient_affected + b_2 * sex + b_3 * age +  time_effects * t + random_slope + noise\n",
    "\n",
    "            data.append([patient_id, t, patient_affected, sex, age, test_score])\n",
    "    return pd.DataFrame(data, columns=['PatientID', 'Time', 'Affected', 'Sex', 'Age', 'Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MixedLMResults' object has no attribute 'df_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Manuelle Berechnung des Likelihood Ratio Tests\u001b[39;00m\n\u001b[0;32m     15\u001b[0m lr_statistic \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (full_fit\u001b[38;5;241m.\u001b[39mllf \u001b[38;5;241m-\u001b[39m reduced_fit\u001b[38;5;241m.\u001b[39mllf)\n\u001b[1;32m---> 16\u001b[0m df_diff \u001b[38;5;241m=\u001b[39m (\u001b[43mfull_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_model\u001b[49m \u001b[38;5;241m-\u001b[39m reduced_fit\u001b[38;5;241m.\u001b[39mdf_model)  \u001b[38;5;66;03m# Freiheitsgrade basierend auf Modellparametern\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# p-Wert aus Chi-Quadrat-Verteilung\u001b[39;00m\n\u001b[0;32m     19\u001b[0m p_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m stats\u001b[38;5;241m.\u001b[39mchi2\u001b[38;5;241m.\u001b[39mcdf(lr_statistic, df_diff)\n",
      "File \u001b[1;32mc:\\Users\\yanni\\anaconda\\envs\\torch_env\\lib\\site-packages\\statsmodels\\base\\wrapper.py:34\u001b[0m, in \u001b[0;36mResultsWrapper.__getattribute__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m     36\u001b[0m how \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_attrs\u001b[38;5;241m.\u001b[39mget(attr)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MixedLMResults' object has no attribute 'df_model'"
     ]
    }
   ],
   "source": [
    "lrt_results = []\n",
    "for _ in range(100):\n",
    "    # Beispielparameter\n",
    "    data = simulate_data(200)\n",
    "\n",
    "    # Modell anpassen\n",
    "    full_model = smf.mixedlm(\"Score ~ Affected + Sex + Age + Time\", data, groups=data[\"PatientID\"], re_formula=\"~Time\")\n",
    "    full_fit = full_model.fit()\n",
    "\n",
    "    # Reduziertes Modell ohne Effekt von 'Sex'\n",
    "    reduced_model = smf.mixedlm(\"Score ~ Affected + Age + Time\", data, groups=data[\"PatientID\"], re_formula=\"~Time\")\n",
    "    reduced_fit = reduced_model.fit()\n",
    "\n",
    "    # Manuelle Berechnung des Likelihood Ratio Tests\n",
    "    lr_statistic = 2 * (full_fit.llf - reduced_fit.llf)\n",
    "    df_diff = (full_fit.df_model - reduced_fit.df_model)  # Freiheitsgrade basierend auf Modellparametern\n",
    "\n",
    "    # p-Wert aus Chi-Quadrat-Verteilung\n",
    "    p_value = 1 - stats.chi2.cdf(lr_statistic, df_diff)\n",
    "\n",
    "    # LRT durchführen\n",
    "    lrt_results.append(p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood_with_decompositions(df, random_effects_keys, fixed_effects_keys):\n",
    "    N = len(df)\n",
    "    n_rand_eff = len(random_effects_keys) + 1\n",
    "    n_fixed_eff = len(fixed_effects_keys) + 1\n",
    "\n",
    "    # Ensure that the diagonal covariance matrix has only positive values\n",
    "    Delta = torch.diag(softplus(D_param))\n",
    "    det_delta = torch.det(Delta)  \n",
    "\n",
    "    Z_list = calculate_Zlist(df, random_effects_keys)\n",
    "    X_list = calculate_Xlist(df, fixed_effects_keys)\n",
    "    Z_tilde_list = [torch.cat((Z_i, Delta)) for Z_i in Z_list]\n",
    "    X_tilde_list = [torch.cat((X_i, torch.zeros((n_rand_eff, n_fixed_eff)))) for X_i in X_list]\n",
    "    Q_list = [QR_decomposition(Z_i)[0] for Z_i in Z_tilde_list]\n",
    "    R11_list = [QR_decomposition(Z_i)[1][:n_rand_eff, :n_rand_eff] for Z_i in Z_tilde_list]\n",
    "    R00_list = [Q_list[i].T @ X_tilde_list[i] for i in range(Z_tilde_list.shape[0])]\n",
    "    sigma2 = 1\n",
    "    c_1 = 1\n",
    "    c_0 = 1\n",
    "    R_00 = 1\n",
    "    beta = 1\n",
    "    likelihood = - N/2 *torch.log(2* torch.pi * sigma2) + ((c_1 + c_0 - R_00 * beta) / (-2* sigma2))\n",
    "    likelihood += torch.log([det_delta / torch.det(R11_i) for R11_i in R11_list]).sum()\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chol_likelihood(df, fixed_effects, random_effects):\n",
    "    n_fixed_eff = len(fixed_effects) + 1\n",
    "    n_rand_eff = len(random_effects) + 1\n",
    "    N = len(df)\n",
    "\n",
    "    D_param = torch.randn(n_rand_eff, requires_grad=True)\n",
    "\n",
    "    # Fixed effects design matrix (Datenmatrix) for each patient\n",
    "    X_list = calculate_Xlist(df, fixed_effects)\n",
    "    # Random effects design matrix (Datenmatrix) for each patient\n",
    "    Z_list = calculate_Zlist(df, random_effects)\n",
    "    # Response variable: Test scores\n",
    "    y = torch.from_numpy(np.array(df['test_score'])).to(torch.float32)\n",
    "\n",
    "    # Augmented response vector y_e (eq. 2.11 p. 65)\n",
    "    y_e = torch.cat([torch.cat((y[get_ind(pat, df)], torch.zeros(n_rand_eff))).unsqueeze(-1) for pat in df['patient_id'].unique()])\n",
    "\n",
    "    # Ensure that the diagonal covariance matrix has only positive values\n",
    "    Delta = torch.diag(torch.nn.functional.softplus(D_param))\n",
    "    # Calculate the Cholesky decomposition of Delta\n",
    "    chol_Delta = torch.linalg.cholesky(Delta)\n",
    "    det_Delta = torch.prod(torch.diag(chol_Delta))**2  # Determinant via Cholesky\n",
    "\n",
    "    # Define Z_tilde and compute Cholesky decompositions for each Z_tilde matrix\n",
    "    Z_tilde_list = [torch.cat((Z_i, chol_Delta)) for Z_i in Z_list]\n",
    "    X_tilde_list = [torch.cat((X_i, torch.zeros((n_rand_eff, n_fixed_eff)))) for X_i in X_list]\n",
    "    # Matrix X_e (eq. 2.11 p. 65)\n",
    "    X_e = torch.cat((block_diag_list(Z_tilde_list), torch.cat(X_tilde_list)), -1)\n",
    "\n",
    "    # Calculate MLE estimates of random and fixed effects with current set of covariance Parameters (eq. 2.11 p. 65)\n",
    "    X_e_T_X_e = X_e.t() @ X_e\n",
    "    chol_X_e_T_X_e = torch.linalg.cholesky(X_e_T_X_e)\n",
    "    inv_X_e_T_X_e = torch.cholesky_inverse(chol_X_e_T_X_e)\n",
    "    pred = inv_X_e_T_X_e @ X_e.t() @ y_e\n",
    "\n",
    "    # Calculate MLE estimates of the noise sigma with current set of covariance Parameters (eq. 2.12 p. 65)\n",
    "    residuals = y_e - X_e @ pred\n",
    "    pred_sigma = torch.sum(residuals ** 2) / N\n",
    "\n",
    "    # Calculate the logarithm of the likelihood function in (eq. 2.13 p. 65)\n",
    "    likelihood = -N/2 * (1 + torch.log(torch.tensor(2 * torch.pi)) + torch.log(pred_sigma))\n",
    "    likelihood += torch.sum(torch.log(torch.diag(chol_X_e_T_X_e))) - torch.sum(torch.log(torch.diag(chol_Delta)))\n",
    "\n",
    "    return -likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(num_simulations): \n",
    "    lrt_results = []\n",
    "    params_full = torch.randn(len(random_effects_keys) + 1, requires_grad=True) #np.array([...]) Startwerte\n",
    "    params_reduced = torch.randn(len(random_effects_keys) + 1, requires_grad=True) #np.array([...]) Startwert\n",
    "    for _ in range(num_simulations):\n",
    "        data = pd.DataFrame(simulate_data(200), columns=['patient_id', 'years_after_treatment', 'familiy_affected', 'sex', 'age', 'test_score'])\n",
    "        # Modelle anpassen\n",
    "        # Hier müssen Sie die Parameterinitialisierung und -optimierung hinzufügen\n",
    "        result_full = minimize(calculate_likelihood_full, params_full, method='bfgs', max_iter=6)\n",
    "        result_reduced = minimize(calculate_likelihood_reduced, params_reduced, method='bfgs', max_iter=6)\n",
    "\n",
    "        # Likelihoods berechnen\n",
    "        log_likelihood_full = -result_full.fun\n",
    "        log_likelihood_reduced = -result_reduced.fun\n",
    "        # LRT durchführen\n",
    "        df_diff = len(params_full) - len(params_reduced)\n",
    "        lrt_stat = likelihood_ratio(log_likelihood_full, log_likelihood_reduced, 1)\n",
    "        lrt_results.append(lrt_stat)\n",
    "    return lrt_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
