{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "from get_models import Progress_Bar, Encoder, Decoder, CovarianceMatrix, thermometer_encode_df\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.normal import Normal\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import chi2\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#vae latent dimension\n",
        "latent_dim = 2\n",
        "\n",
        "def get_ind(id, df):\n",
        "    return np.where(df['patient_id'] == id)[0]\n",
        "\n",
        "def get_design_matrix(df_effects, fixed_effects_keys, random_effects_keys, r=1, include_interaction=False):\n",
        "    patient_id = df_effects['patient_id'].unique()\n",
        "\n",
        "    X_list = [torch.from_numpy(np.array(df_effects.loc[get_ind(id, df_effects), fixed_effects_keys])).to(torch.float32) for id in patient_id]\n",
        "\n",
        "    if include_interaction==True:\n",
        "        for key in random_effects_keys[1:]:\n",
        "            X_list = [torch.cat((X_i, X_i[:,1:] * torch.from_numpy(np.array(df_effects.loc[get_ind(patient_id[j], df_effects), key])).unsqueeze(-1)\n",
        "                                ), -1).to(torch.float32) for j,X_i in enumerate(X_list)]\n",
        "\n",
        "    X_list = [torch.cat((torch.from_numpy(np.array(df_effects.loc[get_ind(patient_id[j], df_effects), 'age'])).unsqueeze(-1), X_i), -1).to(torch.float32) for j,X_i in enumerate(X_list)]\n",
        "\n",
        "\n",
        "    Z_list = [torch.from_numpy(np.array(df_effects.loc[get_ind(id, df_effects), random_effects_keys])).to(torch.float32) for id in patient_id]\n",
        "    Z_list = [torch.block_diag(*[i for j in range(r)]) for i in Z_list]   \n",
        "    X_list = [torch.block_diag(*[i for j in range(r)]) for i in X_list]\n",
        "    return X_list, Z_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize Encoder and Decoder Models and the Mixed Model Parameters. mode='diagonal': Diagonal Covariance Matrix, mode='full': Full Covariance Matrix,\n",
        "def initialize(latent_dim, mode='diagonal'):\n",
        "    encoder = Encoder(\n",
        "        input_dim=69,\n",
        "        hidden_dims=[150], \n",
        "        output_dim=latent_dim, \n",
        "        act=torch.nn.Tanh())\n",
        "\n",
        "    decoder = Decoder(\n",
        "        item_positions=np.concatenate([[i]*a for i,a in enumerate(np.array(test_scores_df[test_scores_df.columns[1:]].max(0)).astype(np.int32))]),                            \n",
        "        input_dim=latent_dim,\n",
        "        hidden_dims=[150], \n",
        "        act=torch.nn.Tanh())\n",
        "\n",
        "    var_param = CovarianceMatrix(q*latent_dim, mode=mode)    \n",
        "    return encoder, decoder, var_param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "#Train the VAE model:  Weighting of the loss function\n",
        "# alpha: kl-divergence weight;  \n",
        "# delta: MSE distance between encoder prediction and decoder; \n",
        "# gamma: decoder reconstruction loss\n",
        "# eta: mixed model loss\n",
        "\n",
        "# batch_size should be greater than 50\n",
        "\n",
        "def train_vae(epochs, batch_size, encoder, decoder, optimizer_vae, alpha=1, gamma=1):\n",
        "    steps = int(len(test_scores_df_encoded) / batch_size)\n",
        "    rng = np.random.default_rng(1234)\n",
        "    prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
        "    #progBar = Progress_Bar(epochs, steps, ['nELBO', 'KL', 'Rec Loss', 'Item Error'])\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        shuffle = rng.permutation(len(test_scores_df_encoded))\n",
        "        \n",
        "        for step in range(steps):\n",
        "            pat_batch = np.arange(len(test_scores_df_encoded))[shuffle[step*batch_size:(step+1)*batch_size]]\n",
        "\n",
        "            test_data = torch.from_numpy(np.array(test_scores_df_encoded.loc[pat_batch])).to(torch.float32)\n",
        "            test_data_orig = torch.from_numpy(np.array(test_scores_df[test_scores_df.columns[1:]].loc[pat_batch])).to(torch.int32)\n",
        "            \n",
        "            optimizer_vae.zero_grad(set_to_none=True)\n",
        "            #encode test scores\n",
        "            mu, log_sig = encoder.encode(test_data)\n",
        "\n",
        "            #reparametrization trick to get latent variables\n",
        "            eps = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
        "            z = mu + log_sig.exp() * eps\n",
        "            \n",
        "            #kl divergence\n",
        "            kl = torch.mean(0.5 * torch.sum(mu.square() + torch.exp(2.0 * log_sig) - 1.0 - (2.0 * log_sig), dim=1))\n",
        "\n",
        "            rec_loss, probs = decoder(z, test_data_orig)\n",
        "            nelbo = alpha * kl + gamma * rec_loss\n",
        "                \n",
        "            nelbo.backward()\n",
        "            optimizer_vae.step()\n",
        "\n",
        "            #data_pred = torch.stack([torch.argmax(pred, dim=-1) for pred in probs]) \n",
        "            # total test item prediction error  \n",
        "            #item_error = np.mean(np.sum(np.abs(data_pred.detach().numpy() - test_data_orig.T.numpy()), axis=0))\n",
        "\n",
        "            # progBar.update({\n",
        "            #     'nELBO': nelbo.item(), \n",
        "            #     'KL': alpha * kl.item(), \n",
        "            #     'Rec Loss': gamma * rec_loss.item(), \n",
        "            #     'Item Error': item_error,\n",
        "            #     }) \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        mu = encoder.encode(torch.from_numpy(np.array(test_scores_df_encoded)).to(torch.float32))[0] \n",
        "        return mu.detach()\n",
        "\n",
        "\n",
        "def calc_likelihood(var_param, Z_list_batch, X_list_batch, z_list):\n",
        "    Phi, sigma = var_param()\n",
        "    N = sum([len(Z_i) for Z_i in Z_list_batch])\n",
        "\n",
        "    V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list_batch]\n",
        "    V_inv_list = [V_i.inverse() for V_i in V_list]\n",
        "    \n",
        "    Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list_batch, V_inv_list)]).sum(dim=0)\n",
        "    Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list_batch, V_inv_list, z_list)]).sum(dim=0)\n",
        "\n",
        "    #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
        "    #if torch.abs(torch.det(Xt_V_inv_X)) > 1e-6:\n",
        "    EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
        "    # EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_batch, Z_list_batch, V_inv_list, z_list)]\n",
        "\n",
        "    residual_list = [y_i - X_i @ EBLUE for y_i, X_i in zip(z_list, X_list_batch)]\n",
        "    #Mixed model prediction\n",
        "    # z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_batch, Z_list_batch, EBLUP_list)]).reshape((-1, latent_dim))\n",
        "\n",
        "    log_det_V = torch.stack([V_i.det().clamp(min=1e-12).log() for V_i in V_list]).sum()\n",
        "    const = torch.log(torch.tensor(2.0 * torch.pi))\n",
        "    rt_V_inv_r = torch.stack([r_i.t() @ V_i_inv @ r_i for r_i, V_i_inv in zip(residual_list, V_inv_list)]).sum()\n",
        "\n",
        "    #negative mixed models likelihood\n",
        "    nML = 0.5 * (log_det_V + rt_V_inv_r + N * const) #/ N   \n",
        "         \n",
        "    return nML\n",
        "\n",
        "def calc_likelihood_full_model(var_param, Z_list_batch, X_list_batch, z_list):\n",
        "    Phi, sigma = var_param()\n",
        "\n",
        "    V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list_batch]\n",
        "    V_inv_list = [V_i.inverse() for V_i in V_list]\n",
        "            \n",
        "    Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list_batch, V_inv_list)]).sum(dim=0)\n",
        "    Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list_batch, V_inv_list, z_list)]).sum(dim=0)\n",
        "\n",
        "    #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
        "    if torch.abs(torch.det(Xt_V_inv_X)) > 1e-6:\n",
        "        EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
        "        EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_batch, Z_list_batch, V_inv_list, z_list)]\n",
        "\n",
        "        #Mixed model prediction\n",
        "        z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_batch, Z_list_batch, EBLUP_list)]).reshape((-1, latent_dim))\n",
        "         \n",
        "    return z_pred\n",
        "\n",
        "def train_vae_2(epochs, batch_size, encoder, decoder, optimizer_vae, Z_list, X_list, var_param, alpha=1, gamma=1, eta=1):\n",
        "    steps = int(num_patients / batch_size)\n",
        "    rng = np.random.default_rng(1234)\n",
        "    prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        shuffle = rng.permutation(num_patients)\n",
        "        \n",
        "        for step in range(steps):\n",
        "            #draw minibatch\n",
        "            pat_batch = patients[shuffle[step*batch_size:(step+1)*batch_size]]\n",
        "            pat_ind_batch = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in pat_batch]\n",
        "            \n",
        "            ind_batch = []\n",
        "            add = 0\n",
        "            for ind in range(len(pat_ind_batch)):\n",
        "                len_i = len(pat_ind_batch[ind])\n",
        "                ind_batch += [torch.arange(add, add + len_i)]\n",
        "                add += len_i\n",
        "\n",
        "            Z_list_batch = [Z_list[pat] for pat in pat_batch]\n",
        "            X_list_batch = [X_list[pat] for pat in pat_batch]\n",
        "            \n",
        "            test_data = torch.concatenate([torch.from_numpy(np.array(test_scores_df_encoded.loc[ind])).to(torch.float32) for ind in pat_ind_batch])\n",
        "            test_data_orig = torch.concatenate([torch.from_numpy(np.array(test_scores_df[test_scores_df.columns[1:]].loc[ind])).to(torch.int32) for ind in pat_ind_batch])\n",
        "            \n",
        "            optimizer_vae.zero_grad(set_to_none=True)\n",
        "            #encode test scores\n",
        "            mu, log_sig = encoder.encode(test_data)\n",
        "\n",
        "            #reparametrization trick to get latent variables\n",
        "            eps = prior.sample(torch.Size([log_sig.size(dim=0)]))\n",
        "            z = mu + log_sig.exp() * eps\n",
        "            \n",
        "            #kl divergence\n",
        "            kl = torch.mean(0.5 * torch.sum(mu.square() + torch.exp(2.0 * log_sig) - 1.0 - (2.0 * log_sig), dim=1))\n",
        "\n",
        "            # get the response variable list (latent z)\n",
        "            z_list = [z[ind].flatten().to(torch.float32) for ind in ind_batch]\n",
        "\n",
        "            #Mixed model loglikelihood loss. Notation follows https://www.sfu.ca/sasdoc/sashtml/stat/chap41/sect23.htm\n",
        "            Phi, sigma = var_param()\n",
        "\n",
        "            V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list_batch]\n",
        "            V_inv_list = [V_i.inverse() for V_i in V_list]\n",
        "            \n",
        "            Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list_batch, V_inv_list)]).sum(dim=0)\n",
        "            Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list_batch, V_inv_list, z_list)]).sum(dim=0)\n",
        "\n",
        "            #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
        "            if torch.abs(torch.det(Xt_V_inv_X)) > 1e-6:\n",
        "                EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
        "                EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_batch, Z_list_batch, V_inv_list, z_list)]\n",
        "        \n",
        "                #Mixed model prediction\n",
        "                z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_batch, Z_list_batch, EBLUP_list)]).reshape((-1, latent_dim))\n",
        "\n",
        "\n",
        "                #distance between encoder latent variables and mixed model prediction\n",
        "                residuals = ((z_pred - z) ** 2).sum(1).mean()\n",
        "\n",
        "                #reconstruction loss\n",
        "                rec_loss, probs = decoder(z_pred, test_data_orig)\n",
        "                nelbo = alpha * kl + eta * residuals + gamma * rec_loss\n",
        "                \n",
        "                nelbo.backward()\n",
        "                optimizer_vae.step()\n",
        "                \n",
        "    with torch.no_grad():\n",
        "        mu = encoder.encode(torch.from_numpy(np.array(test_scores_df_encoded)).to(torch.float32))[0] \n",
        "        return mu.detach()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def likelihood_ratio(L_full, L_red):\n",
        "    return 2 * (L_full - L_red)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "\n",
            "Train full:\n",
            "\n",
            "Train reduced:\n",
            "\n",
            "2nd Training Step\n"
          ]
        },
        {
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'z_pred' where it is not associated with a value",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[29], line 95\u001b[0m\n\u001b[0;32m     90\u001b[0m optimizer_mm_red_2 \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mLBFGS([ \n\u001b[0;32m     91\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: var_param_red\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m}\n\u001b[0;32m     92\u001b[0m ])\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2nd Training Step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m z_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_likelihood_full_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_param_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_list_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_list_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m z \u001b[38;5;241m=\u001b[39m train_vae_2(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m64\u001b[39m, encoder, decoder, optimizer_vae, Z_list_full, X_list_full, var_param_full, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     98\u001b[0m pat_ind_b \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39marange(pat_ind[i], pat_ind[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m patients]\n",
            "Cell \u001b[1;32mIn[27], line 102\u001b[0m, in \u001b[0;36mcalc_likelihood_full_model\u001b[1;34m(var_param, Z_list_batch, X_list_batch, z_list)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m#Mixed model prediction\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     z_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([X_i \u001b[38;5;241m@\u001b[39m EBLUE \u001b[38;5;241m+\u001b[39m Z_i \u001b[38;5;241m@\u001b[39m EBLUP_i \u001b[38;5;28;01mfor\u001b[39;00m X_i, Z_i, EBLUP_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_list_batch, Z_list_batch, EBLUP_list)])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, latent_dim))\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mz_pred\u001b[49m\n",
            "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'z_pred' where it is not associated with a value"
          ]
        }
      ],
      "source": [
        "# RUN SIMULATION FOR n = num_simulations\n",
        "num_simulations = 100\n",
        "\n",
        "lrt_results_before = []  # List to save the results\n",
        "lrt_results_after = []\n",
        "\n",
        "all_epochs_dict = {}  # dictionary to save all models in only one frame\n",
        "\n",
        "fixed_effects_keys_full = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never', 'sex']\n",
        "random_effects_keys_full = ['intercept', 'since_medication', 'since_switch']\n",
        "fixed_effects_keys_red = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never']\n",
        "random_effects_keys_red = ['intercept', 'since_medication', 'since_switch']\n",
        "\n",
        "q = len(random_effects_keys_full)\n",
        "latent_dim = 10  # Assuming some latent dimension\n",
        "\n",
        "for epoch in range(num_simulations):\n",
        "    print('Epoch', epoch)\n",
        "    \n",
        "    # Load dataframes\n",
        "    test_scores_df = pd.read_csv(os.getcwd()+'/test_scores.csv')\n",
        "    test_scores_df_encoded = thermometer_encode_df(test_scores_df, test_scores_df.columns[1:])\n",
        "    time_df = pd.read_csv(os.getcwd()+'/time_df.csv')\n",
        "    time_df['intercept'] = np.ones(time_df.shape[0])\n",
        "    baseline_df = pd.read_csv(os.getcwd()+'/baseline_df.csv')\n",
        "    baseline_df['sex'] = np.random.randint(2, size=baseline_df.shape[0])\n",
        "    df_effects = pd.merge(baseline_df, time_df, on='patient_id', how='inner')\n",
        "    \n",
        "    patients = torch.from_numpy(np.array(baseline_df['patient_id']))\n",
        "    num_patients = len(patients)\n",
        "    \n",
        "    X_list_full, Z_list_full = get_design_matrix(df_effects, fixed_effects_keys_full, random_effects_keys_full, r=latent_dim)\n",
        "    X_list_red, Z_list_red = get_design_matrix(df_effects, fixed_effects_keys_red, random_effects_keys_red, r=latent_dim)   \n",
        "    pat_ind = np.cumsum([0]+[int(len(X_i)/latent_dim) for X_i in X_list_full])\n",
        "    \n",
        "    encoder, decoder = initialize(latent_dim)[0:2]\n",
        "    optimizer_vae = optim.Adam([ \n",
        "        {'params': encoder.parameters(), 'lr': 0.01},  \n",
        "        {'params': decoder.parameters(), 'lr': 0.01}\n",
        "    ])\n",
        "    \n",
        "    var_param_full = CovarianceMatrix(q * latent_dim, mode='diagonal')    \n",
        "    var_param_red = CovarianceMatrix(q * latent_dim, mode='diagonal')    \n",
        "\n",
        "    for _ in range(1):\n",
        "        optimizer_mm_full = optim.LBFGS([ \n",
        "            {'params': var_param_full.parameters(), 'lr': 1.0}\n",
        "        ])\n",
        "\n",
        "        optimizer_mm_red = optim.LBFGS([ \n",
        "            {'params': var_param_red.parameters(), 'lr': 1.0}\n",
        "        ])\n",
        "        \n",
        "        z = train_vae(150, 100, encoder, decoder, optimizer_vae)\n",
        "\n",
        "        pat_ind_b = [torch.arange(pat_ind[i], pat_ind[i+1]) for i in patients]\n",
        "        z_list = [z[ind].flatten().to(torch.float32) for ind in pat_ind_b]\n",
        "        \n",
        "        steps = 300\n",
        "\n",
        "        print('\\nTrain full:')\n",
        "        for _ in range(steps):\n",
        "            def closure_full():\n",
        "                optimizer_mm_full.zero_grad()\n",
        "                nML_full = calc_likelihood(var_param_full, Z_list_full, X_list_full, z_list)\n",
        "                nML_full.backward()\n",
        "                return nML_full\n",
        "\n",
        "            optimizer_mm_full.step(closure_full)       \n",
        "\n",
        "        print('\\nTrain reduced:')\n",
        "        for _ in range(steps):\n",
        "            def closure_red():\n",
        "                optimizer_mm_red.zero_grad()\n",
        "                nML_red = calc_likelihood(var_param_red, Z_list_red, X_list_red, z_list)\n",
        "                nML_red.backward()\n",
        "                return nML_red\n",
        "\n",
        "            optimizer_mm_red.step(closure_red)\n",
        "\n",
        "    lrt_results_before.append(likelihood_ratio(closure_full(), closure_red()))\n",
        "\n",
        "    var_param_full_2 = CovarianceMatrix(q * latent_dim, mode='diagonal')    \n",
        "    var_param_red_2 = CovarianceMatrix(q * latent_dim, mode='diagonal')    \n",
        "        \n",
        "    optimizer_mm_full_2 = optim.LBFGS([ \n",
        "        {'params': var_param_full.parameters(), 'lr': 1.0}\n",
        "    ])\n",
        "\n",
        "    optimizer_mm_red_2 = optim.LBFGS([ \n",
        "        {'params': var_param_red.parameters(), 'lr': 1.0}\n",
        "    ])\n",
        "        \n",
        "    print(\"\\n2nd Training Step\")\n",
        "    z_pred = calc_likelihood_full_model(var_param_full, Z_list_full, X_list_full, z_list)\n",
        "    z = train_vae_2(50, 64, encoder, decoder, optimizer_vae, Z_list_full, X_list_full, var_param_full, alpha=1, gamma=1, eta=1)\n",
        "\n",
        "    pat_ind_b = [torch.arange(pat_ind[i], pat_ind[i+1]) for i in patients]\n",
        "    z_list = [z[ind].flatten().to(torch.float32) for ind in pat_ind_b]\n",
        "        \n",
        "    print('\\nTrain full after:')\n",
        "    for _ in range(steps):\n",
        "        def closure_full_2():\n",
        "            optimizer_mm_full_2.zero_grad()\n",
        "            nML_full_after = calc_likelihood(var_param_full, Z_list_full, X_list_full, z_list)\n",
        "            nML_full_after.backward()\n",
        "            return nML_full_after\n",
        "\n",
        "        optimizer_mm_full_2.step(closure_full_2)\n",
        "\n",
        "    print('\\nTrain reduced after:')\n",
        "    for _ in range(steps):\n",
        "        def closure_red_2():\n",
        "            optimizer_mm_red_2.zero_grad()\n",
        "            nML_red_after = calc_likelihood(var_param_red, Z_list_red, X_list_red, z_list)\n",
        "            nML_red_after.backward()\n",
        "            return nML_red_after\n",
        "\n",
        "        optimizer_mm_red_2.step(closure_red_2)\n",
        "        \n",
        "    lrt_results_after.append(likelihood_ratio(closure_full_2(), closure_red_2()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lrt_hist1 = []\n",
        "for val in lrt_results_after:\n",
        "    if -200 < val < 0:\n",
        "        lrt_hist1.append(val) \n",
        "\n",
        "# plot the histogr<am of the LRT-statistic\n",
        "plt.hist(np.array(torch.stack(lrt_results_after).detach()), bins=50, density=True, alpha=0.6, color='g')\n",
        "# x = np.linspace(-8000, 8000, 100)\n",
        "# plt.plot(x, chi2.pdf(x + 500, df=1), 'r-', lw=2, label='Chi-Quadrat-Verteilung (df=1)')\n",
        "\n",
        "#x = np.linspace(0, 10, 100)\n",
        "#plt.plot(-x, chi2.pdf(x, df=1), 'r-', lw=1, label='Chi-Squared (df=1)')\n",
        "\n",
        "# Beschriftungen hinzufügen\n",
        "plt.title('Histogramm der Likelihood-Ratio-Teststatistiken')\n",
        "plt.xlabel('Teststatistik')\n",
        "plt.ylabel('Häufigkeit')\n",
        "plt.legend()\n",
        "\n",
        "# Histogramm anzeigen\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "stack expects a non-empty TensorList",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[57], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m val \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      4\u001b[0m         lrt_hist\u001b[38;5;241m.\u001b[39mappend(val) \n\u001b[1;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlrt_hist\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()), bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, density\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;241m-\u001b[39mx, chi2\u001b[38;5;241m.\u001b[39mpdf(x, df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr-\u001b[39m\u001b[38;5;124m'\u001b[39m, lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChi-Squared (df=1)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
          ]
        }
      ],
      "source": [
        "\n",
        "lrt_hist = []\n",
        "for val in lrt_results_before:\n",
        "    if -400 < val < 0:\n",
        "        lrt_hist.append(val) \n",
        "\n",
        "plt.hist(np.array(torch.stack(lrt_hist).detach()), bins=50, density=True, alpha=0.6, color='b')\n",
        "\n",
        "\n",
        "x = np.linspace(0, 10, 100)\n",
        "plt.plot(-x, chi2.pdf(x, df=1), 'r-', lw=1, label='Chi-Squared (df=1)')\n",
        "\n",
        "# Beschriftungen hinzufügen\n",
        "plt.title('Histogramm der Likelihood-Ratio-Teststatistiken')\n",
        "plt.xlabel('Teststatistik')\n",
        "plt.ylabel('Häufigkeit')\n",
        "plt.legend()\n",
        "\n",
        "# Histogramm anzeigen\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
