{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from get_models import Progress_Bar, Encoder, Decoder, CovarianceMatrix, thermometer_encode_df\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "from torchmin import minimize\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2\n",
    "from torchmin import minimize\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae latent dimension\n",
    "latent_dim = 1\n",
    "\n",
    "def get_ind(id, df):\n",
    "    return np.where(df['patient_id'] == id)[0]\n",
    "\n",
    "def get_design_matrix(df_effects, fixed_effects_keys, random_effects_keys, r=1, include_interaction=False):\n",
    "    patient_id = df_effects['patient_id'].unique()\n",
    "\n",
    "    X_list = [torch.from_numpy(np.array(df_effects.loc[get_ind(id, df_effects), fixed_effects_keys])).to(torch.float32) for id in patient_id]\n",
    "\n",
    "    if include_interaction==True:\n",
    "        for key in random_effects_keys[1:]:\n",
    "            X_list = [torch.cat((X_i, X_i[:,1:] * torch.from_numpy(np.array(df_effects.loc[get_ind(patient_id[j], df_effects), key])).unsqueeze(-1)\n",
    "                                ), -1).to(torch.float32) for j,X_i in enumerate(X_list)]\n",
    "\n",
    "    X_list = [torch.cat((torch.from_numpy(np.array(df_effects.loc[get_ind(patient_id[j], df_effects), 'age'])).unsqueeze(-1), X_i), -1).to(torch.float32) for j,X_i in enumerate(X_list)]\n",
    "\n",
    "\n",
    "    Z_list = [torch.from_numpy(np.array(df_effects.loc[get_ind(id, df_effects), random_effects_keys])).to(torch.float32) for id in patient_id]\n",
    "    Z_list = [torch.block_diag(*[i for j in range(r)]) for i in Z_list]   \n",
    "    X_list = [torch.block_diag(*[i for j in range(r)]) for i in X_list]\n",
    "    return X_list, Z_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Encoder and Decoder Models and the Mixed Model Parameters. mode='diagonal': Diagonal Covariance Matrix, mode='full': Full Covariance Matrix,\n",
    "def initialize(latent_dim, mode='diagonal'):\n",
    "    encoder = Encoder(\n",
    "        input_dim=np.shape(test_scores_df_encoded)[-1],\n",
    "        hidden_dims=[150],\n",
    "        output_dim=latent_dim, \n",
    "        act=torch.nn.Tanh())\n",
    "\n",
    "    decoder = Decoder(\n",
    "        item_positions=np.concatenate([[i]*a for i,a in enumerate(np.array(test_scores_df[test_scores_df.columns[1:]].max(0)).astype(np.int32))]),                            \n",
    "        input_dim=latent_dim,\n",
    "        hidden_dims=[150], \n",
    "        act=torch.nn.Tanh())\n",
    "\n",
    "    var_param = CovarianceMatrix(q*latent_dim, mode=mode)    \n",
    "    return encoder, decoder, var_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_ratio(L_full, L_red):\n",
    "    return 2 * (L_full - L_red)\n",
    "\n",
    "def train_vae(epochs, batch_size, encoder, decoder, optimizer_vae, alpha=1, gamma=1):\n",
    "    steps = int(len(test_scores_df_encoded) / batch_size)\n",
    "    rng = np.random.default_rng(1234)\n",
    "    prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
    "    #progBar = Progress_Bar(epochs, steps, ['nELBO', 'KL', 'Rec Loss', 'Item Error'])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        shuffle = rng.permutation(len(test_scores_df_encoded))\n",
    "        \n",
    "        for step in range(steps):\n",
    "            pat_batch = np.arange(len(test_scores_df_encoded))[shuffle[step*batch_size:(step+1)*batch_size]]\n",
    "\n",
    "            test_data = torch.from_numpy(np.array(test_scores_df_encoded.loc[pat_batch])).to(torch.float32)\n",
    "            test_data_orig = torch.from_numpy(np.array(test_scores_df[test_scores_df.columns[1:]].loc[pat_batch])).to(torch.int32)\n",
    "\n",
    "            optimizer_vae.zero_grad(set_to_none=True)\n",
    "            #encode test scores\n",
    "            mu, log_sig = encoder.encode(test_data)\n",
    "\n",
    "            #reparametrization trick to get latent variables\n",
    "            eps = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
    "            z = mu + log_sig.exp() * eps\n",
    "\n",
    "            #kl divergence\n",
    "            kl = torch.mean(0.5 * torch.sum(mu.square() + torch.exp(2.0 * log_sig) - 1.0 - (2.0 * log_sig), dim=1))\n",
    "\n",
    "            rec_loss, probs = decoder(z, test_data_orig)\n",
    "            nelbo = alpha * kl + gamma * rec_loss\n",
    "\n",
    "            nelbo.backward()\n",
    "            optimizer_vae.step()\n",
    "\n",
    "            #data_pred = torch.stack([torch.argmax(pred, dim=-1) for pred in probs]) \n",
    "            # total test item prediction error  \n",
    "            #item_error = np.mean(np.sum(np.abs(data_pred.detach().numpy() - test_data_orig.T.numpy()), axis=0))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mu, log_sig = encoder.encode(torch.from_numpy(np.array(test_scores_df_encoded)).to(torch.float32))\n",
    "        epsilon = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
    "\n",
    "        z = mu + log_sig.exp() * epsilon\n",
    "        return z.detach()\n",
    "\n",
    "\n",
    "def calc_likelihood(var_param, Z_list, X_list, z_list):\n",
    "    Phi, sigma = var_param()\n",
    "    N = sum([len(Z_i) for Z_i in Z_list])\n",
    "\n",
    "    V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list]\n",
    "    # epsilon = 1e-5  # Regularisierungswert\n",
    "    # V_inv_list = [(V_i + epsilon * torch.eye(V_i.size(0))).inverse() for V_i in V_list]\n",
    "    V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "    \n",
    "    Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list, V_inv_list)]).sum(dim=0)\n",
    "    Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "    #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
    "    \n",
    "    EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "    #EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_batch, Z_list_batch, V_inv_list, z_list)]\n",
    "\n",
    "    residual_list = [y_i - X_i @ EBLUE for y_i, X_i in zip(z_list, X_list)]\n",
    "    #Mixed model prediction\n",
    "    #z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_batch, Z_list_batch, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "\n",
    "    log_det_V = torch.stack([V_i.det().clamp(min=1e-12).log() for V_i in V_list]).sum()\n",
    "    const = torch.log(torch.tensor(2.0 * torch.pi))\n",
    "    rt_V_inv_r = torch.stack([r_i.t() @ V_i_inv @ r_i for r_i, V_i_inv in zip(residual_list, V_inv_list)]).sum()\n",
    "\n",
    "        #negative mixed models likelihood\n",
    "    nML = 0.5 * (log_det_V + rt_V_inv_r + N * const) #/ N   \n",
    "         \n",
    "    return nML \n",
    "\n",
    "\n",
    "def train_vae_2(epochs, batch_size, encoder, decoder, optimizer_vae, Z_list, X_list, var_param, alpha=1, gamma=1, eta=1, beta=1):\n",
    "    steps = int(num_patients / batch_size)\n",
    "    rng = np.random.default_rng(1234)\n",
    "    prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        shuffle = rng.permutation(num_patients)\n",
    "        \n",
    "        for step in range(steps):\n",
    "            #draw minibatch\n",
    "            pat_batch = patients[shuffle[step*batch_size:(step+1)*batch_size]]\n",
    "            pat_ind_batch = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in pat_batch]\n",
    "            \n",
    "            ind_batch = []\n",
    "            add = 0\n",
    "            for ind in range(len(pat_ind_batch)):\n",
    "                len_i = len(pat_ind_batch[ind])\n",
    "                ind_batch += [torch.arange(add, add + len_i)]\n",
    "                add += len_i\n",
    "\n",
    "            Z_list_batch = [Z_list[pat] for pat in pat_batch]\n",
    "            X_list_batch = [X_list[pat] for pat in pat_batch]\n",
    "            \n",
    "            test_data = torch.concatenate([torch.from_numpy(np.array(test_scores_df_encoded.loc[ind])).to(torch.float32) for ind in pat_ind_batch])\n",
    "            test_data_orig = torch.concatenate([torch.from_numpy(np.array(test_scores_df[test_scores_df.columns[1:]].loc[ind])).to(torch.int32) for ind in pat_ind_batch])\n",
    "            \n",
    "            optimizer_vae.zero_grad(set_to_none=True)\n",
    "            #encode test scores\n",
    "            mu, log_sig = encoder.encode(test_data)\n",
    "\n",
    "            #reparametrization trick to get latent variables\n",
    "            eps = prior.sample(torch.Size([log_sig.size(dim=0)]))\n",
    "            z = mu + log_sig.exp() * eps\n",
    "            \n",
    "            #kl divergence\n",
    "            kl = torch.mean(0.5 * torch.sum(mu.square() + torch.exp(2.0 * log_sig) - 1.0 - (2.0 * log_sig), dim=1))\n",
    "\n",
    "            # get the response variable list (latent z)\n",
    "            z_list = [z[ind].flatten().to(torch.float32) for ind in ind_batch]\n",
    "\n",
    "            #Mixed model loglikelihood loss. Notation follows https://www.sfu.ca/sasdoc/sashtml/stat/chap41/sect23.htm\n",
    "            Phi, sigma = var_param()\n",
    "\n",
    "            V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list_batch]\n",
    "            V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "            \n",
    "            Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list_batch, V_inv_list)]).sum(dim=0)\n",
    "            Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list_batch, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "            #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
    "            if torch.abs(torch.det(Xt_V_inv_X)) > 1e-6:\n",
    "                EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "                EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_batch, Z_list_batch, V_inv_list, z_list)]\n",
    "        \n",
    "                #Mixed model prediction\n",
    "                z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_batch, Z_list_batch, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "\n",
    "\n",
    "                #distance between encoder latent variables and mixed model prediction\n",
    "                residuals = ((z_pred - z) ** 2).sum(1).mean()\n",
    "\n",
    "                nML = calc_likelihood(var_param, Z_list_batch, X_list_batch, z_list)\n",
    "\n",
    "                #reconstruction loss\n",
    "                rec_loss, probs = decoder(z_pred, test_data_orig)\n",
    "\n",
    "                #loss function\n",
    "                nelbo = alpha * kl + eta * residuals + gamma * rec_loss + beta * nML\n",
    "                \n",
    "                nelbo.backward()\n",
    "                optimizer_vae.step()    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mu, log_sig = encoder.encode(torch.from_numpy(np.array(test_scores_df_encoded)).to(torch.float32))\n",
    "        epsilon = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
    "\n",
    "        z = mu + log_sig.exp() * epsilon\n",
    "        return z.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "_LinAlgError",
     "evalue": "linalg.inv: The diagonal element 18 is zero, the inversion could not be completed because the input matrix is singular.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_LinAlgError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m         res\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m---> 70\u001b[0m     \u001b[43moptimizer_mm_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     72\u001b[0m var_param_red \u001b[38;5;241m=\u001b[39m CovarianceMatrix(q\u001b[38;5;241m*\u001b[39mlatent_dim, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagonal\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     73\u001b[0m optimizer_mm_red \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mLBFGS([ \n\u001b[0;32m     74\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: var_param_red\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.25\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory_size\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m200\u001b[39m}\n\u001b[0;32m     81\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\yanni\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yanni\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yanni\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\optim\\lbfgs.py:440\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter \u001b[38;5;241m!=\u001b[39m max_iter:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# re-evaluate function only if not in last iteration\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;66;03m# the reason we do this: in a stochastic setting,\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m# no use to re-evaluate that function here\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 440\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    441\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[0;32m    442\u001b[0m     opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[1;32mc:\\Users\\yanni\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 66\u001b[0m, in \u001b[0;36mclosure\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m():\n\u001b[0;32m     65\u001b[0m     optimizer_mm_full\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 66\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_param_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_list_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_list_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     res\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "Cell \u001b[1;32mIn[37], line 55\u001b[0m, in \u001b[0;36mcalc_likelihood\u001b[1;34m(var_param, Z_list, X_list, z_list)\u001b[0m\n\u001b[0;32m     52\u001b[0m V_list \u001b[38;5;241m=\u001b[39m [Z_i \u001b[38;5;241m@\u001b[39m Phi \u001b[38;5;241m@\u001b[39m Z_i\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(Z_i\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m*\u001b[39m sigma \u001b[38;5;28;01mfor\u001b[39;00m Z_i \u001b[38;5;129;01min\u001b[39;00m Z_list]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# epsilon = 1e-5  # Regularisierungswert\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# V_inv_list = [(V_i + epsilon * torch.eye(V_i.size(0))).inverse() for V_i in V_list]\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m V_inv_list \u001b[38;5;241m=\u001b[39m [V_i\u001b[38;5;241m.\u001b[39minverse() \u001b[38;5;28;01mfor\u001b[39;00m V_i \u001b[38;5;129;01min\u001b[39;00m V_list]\n\u001b[0;32m     57\u001b[0m Xt_V_inv_X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([X_i\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m@\u001b[39m V_i_inv \u001b[38;5;241m@\u001b[39m X_i \u001b[38;5;28;01mfor\u001b[39;00m X_i, V_i_inv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_list, V_inv_list)])\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     58\u001b[0m Xt_V_inv_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([X_i\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m@\u001b[39m V_i_inv \u001b[38;5;241m@\u001b[39m y_i \u001b[38;5;28;01mfor\u001b[39;00m X_i, V_i_inv, y_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_list, V_inv_list, z_list)])\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[37], line 55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     52\u001b[0m V_list \u001b[38;5;241m=\u001b[39m [Z_i \u001b[38;5;241m@\u001b[39m Phi \u001b[38;5;241m@\u001b[39m Z_i\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(Z_i\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m*\u001b[39m sigma \u001b[38;5;28;01mfor\u001b[39;00m Z_i \u001b[38;5;129;01min\u001b[39;00m Z_list]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# epsilon = 1e-5  # Regularisierungswert\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# V_inv_list = [(V_i + epsilon * torch.eye(V_i.size(0))).inverse() for V_i in V_list]\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m V_inv_list \u001b[38;5;241m=\u001b[39m [\u001b[43mV_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m V_i \u001b[38;5;129;01min\u001b[39;00m V_list]\n\u001b[0;32m     57\u001b[0m Xt_V_inv_X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([X_i\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m@\u001b[39m V_i_inv \u001b[38;5;241m@\u001b[39m X_i \u001b[38;5;28;01mfor\u001b[39;00m X_i, V_i_inv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_list, V_inv_list)])\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     58\u001b[0m Xt_V_inv_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([X_i\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m@\u001b[39m V_i_inv \u001b[38;5;241m@\u001b[39m y_i \u001b[38;5;28;01mfor\u001b[39;00m X_i, V_i_inv, y_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_list, V_inv_list, z_list)])\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31m_LinAlgError\u001b[0m: linalg.inv: The diagonal element 18 is zero, the inversion could not be completed because the input matrix is singular."
     ]
    }
   ],
   "source": [
    "num_simulations = 1000\n",
    "iterations = 30\n",
    "lrt_results = []\n",
    "\n",
    "all_epochs_dict = {} #dictionary to save all models\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_parameters')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "fixed_effects_keys_full = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never', 'sex']\n",
    "random_effects_keys_full = ['intercept', 'since_medication', 'since_switch']\n",
    "# reduced model without fixed effect 'sex' \n",
    "fixed_effects_keys_red = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never']\n",
    "random_effects_keys_red = ['intercept', 'since_medication', 'since_switch']\n",
    "q = len(random_effects_keys_full)\n",
    "\n",
    "for i in range(num_simulations): \n",
    "    print(f\"Epoch: {i}\")\n",
    "    #prepare dataset\n",
    "    test_scores_df = pd.read_csv(os.getcwd()+'/test_scores.csv')\n",
    "    test_scores_df_encoded = thermometer_encode_df(test_scores_df, test_scores_df.columns[1:])\n",
    "    time_df = pd.read_csv(os.getcwd()+'/time_df.csv')\n",
    "    time_df['intercept'] = np.ones(time_df.shape[0])\n",
    "    baseline_df = pd.read_csv(os.getcwd()+'/baseline_df.csv')\n",
    "    baseline_df['sex'] = np.random.randint(2, size=baseline_df.shape[0])\n",
    "    df_effects = pd.merge(baseline_df, time_df, on='patient_id', how='inner')\n",
    "\n",
    "    patients = torch.from_numpy(np.array(baseline_df['patient_id']))\n",
    "    num_patients = len(patients)\n",
    "\n",
    "    X_list_full, Z_list_full = get_design_matrix(df_effects, fixed_effects_keys_full, random_effects_keys_full, r=latent_dim)\n",
    "    X_list_red, Z_list_red = get_design_matrix(df_effects, fixed_effects_keys_red, random_effects_keys_red, r=latent_dim)   \n",
    "    \n",
    "    pat_ind = np.cumsum([0]+[int(len(X_i)/latent_dim) for X_i in X_list_full])\n",
    "\n",
    "    encoder, decoder = initialize(latent_dim)[0:2]\n",
    "    optimizer_vae = torch.optim.Adam([ \n",
    "        {'params': encoder.parameters(), 'lr': 0.01},  \n",
    "        {'params': decoder.parameters(), 'lr': 0.01},  \n",
    "    ])  \n",
    "    z = train_vae(2, 128, encoder, decoder, optimizer_vae)\n",
    "    pat_ind_b = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in patients]\n",
    "\n",
    "    for j in range(iterations):\n",
    "        # print(f\"Iteration: {j}\")\n",
    "        if j != 0:\n",
    "            # calc_likelihood(var_param_full, Z_list_full, X_list_full, z_list)\n",
    "            z = train_vae_2(1, 128, encoder, decoder, optimizer_vae, Z_list_full, X_list_full, var_param_full, alpha=1, gamma=1, eta=10, beta = 10)\n",
    "        \n",
    "        z_list = [z[ind].flatten().to(torch.float32) for ind in pat_ind_b]\n",
    "        \n",
    "        var_param_full = CovarianceMatrix(q*latent_dim, mode='diagonal')  \n",
    "\n",
    "        optimizer_mm_full = torch.optim.LBFGS([ \n",
    "            {'params': var_param_full.parameters(),\n",
    "            'lr': 0.25, \n",
    "            'max_iter':200, \n",
    "            'max_eval': 500, \n",
    "            'tolerance_grad':1e-09, \n",
    "            'tolerance_change':1e-11, \n",
    "            'history_size':200}\n",
    "        ])\n",
    "        \n",
    "        def closure():\n",
    "            optimizer_mm_full.zero_grad()\n",
    "            res = calc_likelihood(var_param_full, Z_list_full, X_list_full, z_list)\n",
    "            res.backward()\n",
    "            return res\n",
    "        \n",
    "        optimizer_mm_full.step(closure) \n",
    "\n",
    "    var_param_red = CovarianceMatrix(q*latent_dim, mode='diagonal') \n",
    "    optimizer_mm_red = torch.optim.LBFGS([ \n",
    "        {'params': var_param_red.parameters(),\n",
    "        'lr': 0.25, \n",
    "        'max_iter':200, \n",
    "        'max_eval': 500, \n",
    "        'tolerance_grad':1e-09, \n",
    "        'tolerance_change':1e-11, \n",
    "        'history_size':200}\n",
    "    ])\n",
    "\n",
    "    def closure_red():\n",
    "        optimizer_mm_red.zero_grad()\n",
    "        res = calc_likelihood(var_param_red, Z_list_red, X_list_red, z_list)\n",
    "        res.backward()\n",
    "        return res\n",
    "        \n",
    "    optimizer_mm_red.step(closure_red)\n",
    "    \n",
    "    res_full = calc_likelihood(var_param_full, Z_list_full, X_list_full, z_list)\n",
    "    res_red = calc_likelihood(var_param_red, Z_list_red, X_list_red, z_list)\n",
    "    \n",
    "    lrt_val = likelihood_ratio(res_full, res_red).detach()\n",
    "    lrt_results.append(lrt_val)\n",
    "\n",
    "    print(f\"\\n LRT Value: {lrt_val}\")\n",
    "\n",
    "    all_epochs_dict[f'epoch_{i}'] = {\n",
    "        'encoder_state_dict': encoder.state_dict(),\n",
    "        'decoder_state_dict': decoder.state_dict(),\n",
    "        'var_param_full': var_param_full,\n",
    "        'optimizer_vae_state_dict': optimizer_vae.state_dict(),\n",
    "        'var_param_red': var_param_red,\n",
    "        'optimizer_mm_full': optimizer_mm_full,\n",
    "        'optimizer_mm_red': optimizer_mm_red,\n",
    "        'X_list_full' : X_list_full,\n",
    "        'Z_list_full' : Z_list_full,\n",
    "        'X_list_red' : X_list_red,\n",
    "        'Z_list_red' : Z_list_red,\n",
    "        'z_list': z_list,\n",
    "        'lrt_val': lrt_val\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "torch.save(lrt_results, os.path.join(save_dir, 'params_nML_in_lossfkt.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.load('hist_likelihood_vae.npy')\n",
    "\n",
    "hist_vals = []\n",
    "\n",
    "for val in data:\n",
    "    hist_vals.append(-val)\n",
    "\n",
    "# plot the histogr<am of the LRT-statistic\n",
    "plt.hist(hist_vals, bins=100, density=True, alpha=0.6, color='g', label='Histogramm der LRT-Statistik')\n",
    "\n",
    "# Chi-Quadrat-Verteilung mit zwei Freiheitsgraden plotten (für Vergleich)\n",
    "x = np.linspace(0, 10, 1000)\n",
    "plt.plot(x, chi2.pdf(x, df=1), 'r-', lw=1, label='Chi-Squared (df=1)')\n",
    "\n",
    "\n",
    "# Beschriftungen hinzufügen\n",
    "plt.title('Histogramm der Likelihood-Ratio-Teststatistiken')\n",
    "plt.xlabel('Teststatistik')\n",
    "plt.ylabel('Häufigkeit')\n",
    "plt.legend()\n",
    "\n",
    "# Save the histogram in the current directory\n",
    "histogram_path = os.path.join(os.getcwd(), 'hist_nML_in_lossfkt.png')\n",
    "plt.savefig(histogram_path)\n",
    "\n",
    "# Histogramm anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_vae(300, 60,X_list, Z_list, encoder, decoder, var_param, optimizer_vae, alpha=1, gamma=1, delta=1, eta=1)  \n",
    "# get the model prediction:\n",
    "# def eval_vae(X_list, Z_list, var_param, encoder):\n",
    "#     with torch.no_grad():\n",
    "#         pat_ind_batch = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in patients]\n",
    "#         prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
    "\n",
    "#         test_data = torch.concatenate([torch.from_numpy(np.array(test_scores_df_encoded.loc[ind])).to(torch.float32) for ind in pat_ind_batch])\n",
    "\n",
    "#         mu, log_sig = encoder.encode(test_data)\n",
    "\n",
    "#         eps = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
    "#         z = mu + log_sig.exp() * eps # latent data\n",
    "\n",
    "#         z_list = [z[ind].flatten().to(torch.float32) for ind in pat_ind_batch]\n",
    "\n",
    "#         Phi, sigma = var_param()\n",
    "#         N = sum([len(Z_i) for Z_i in Z_list])\n",
    "\n",
    "#         V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list]\n",
    "#         V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "        \n",
    "#         Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list, V_inv_list)]).sum(dim=0)\n",
    "#         Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "#         EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "#         EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list, Z_list, V_inv_list, z_list)]\n",
    "\n",
    "#         residual_list = [y_i - X_i @ EBLUE for y_i, X_i in zip(z_list, X_list)]\n",
    "#         z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list, Z_list, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "\n",
    "#         log_det_V = torch.stack([V_i.det().clamp(min=1e-12).log() for V_i in V_list]).sum()\n",
    "#         const = torch.log(torch.tensor(2.0 * torch.pi))\n",
    "#         rt_V_inv_r = torch.stack([r_i.t() @ V_i_inv @ r_i for r_i, V_i_inv in zip(residual_list, V_inv_list)]).sum()\n",
    "\n",
    "#         nML = 0.5 * (log_det_V + rt_V_inv_r + N * const) \n",
    "#         return mu, z, z_pred, nML\n",
    "\n",
    "# def calc_likelihood_full_model(var_param, Z_list_full, X_list_full, z_list):\n",
    "#     if isinstance(var_param, CovarianceMatrix):\n",
    "#         Phi, sigma = var_param.forward()  # Verwenden Sie die forward-Methode korrekt\n",
    "#     else:\n",
    "#         raise TypeError(\"var_param must be an instance of CovarianceMatrix\")\n",
    "\n",
    "#     N = sum([len(Z_i) for Z_i in Z_list_full])\n",
    "#     V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list_full]\n",
    "#     V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "            \n",
    "#     Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list_full, V_inv_list)]).sum(dim=0)\n",
    "#     Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list_full, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "#     #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
    "#     if torch.abs(torch.det(Xt_V_inv_X)) > 1e-6:\n",
    "#         EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "#         EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_full, Z_list_full, V_inv_list, z_list)]\n",
    "\n",
    "#         #Mixed model prediction\n",
    "#         z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_full, Z_list_full, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "         \n",
    "#     return z_pred\n",
    "\n",
    "\n",
    "# def optimize_mixed_model(closure, params):\n",
    "#     # Stellen Sie sicher, dass params in einen Tensor umgewandelt werden können\n",
    "#     if isinstance(params, CovarianceMatrix):\n",
    "#         x0 = params.L_param\n",
    "#     else:\n",
    "#         x0 = torch.as_tensor(params)\n",
    "    \n",
    "#     result = minimize(closure, x0, method='bfgs', max_iter=6)\n",
    "#     return result\n",
    "\n",
    "    # optimizer_mm_full = optim.LBFGS(var_param_full.parameters(), lr=1.0)\n",
    "    # optimizer_mm_red = optim.LBFGS(var_param_red.parameters(), lr=1.0)\n",
    "    #ohne batches\n",
    "    #res = minimize(calc_likelihood_full, var_param_full.parameters(), method='bfgs', max_iter=6)\n",
    "\n",
    "\n",
    "    # def closure():\n",
    "    #     optimizer_mm_full.zero_grad()\n",
    "    #     res = calc_likelihood_full(var_param_full)\n",
    "    #     res.backward()\n",
    "    #     return res\n",
    "        \n",
    "    # optimizer_mm_full.step(closure)\n",
    "\n",
    "    # res_full = minimize(calc_likelihood_full, var_param_full.parameters(), method='bfgs', max_iter=6)\n",
    "    # res_red = minimize(calc_likelihood_red, var_param_red.parameters(), method='bfgs', max_iter=6)\n",
    "\n",
    "    # steps = 300\n",
    "    # print('\\nTrain full:')\n",
    "    # for j in range(steps):\n",
    "    #     optimizer_mm_full.zero_grad(set_to_none=True)\n",
    "    #     res_full = calc_likelihood_full(var_param_full)\n",
    "    #     res_full.backward()\n",
    "    #     optimizer_mm_full.step()\n",
    "\n",
    "    # print('\\nTrain reduced:')\n",
    "    # for k in range(steps):\n",
    "    #     optimizer_mm_red.zero_grad(set_to_none=True)\n",
    "    #     res_red = calc_likelihood_red(var_param_red)\n",
    "    #     res_red.backward()\n",
    "    #     optimizer_mm_red.step() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
