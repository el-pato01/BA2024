{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from get_models import Progress_Bar, Encoder, Decoder, CovarianceMatrix, thermometer_encode_df\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "from torchmin import minimize\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2\n",
    "from torchmin import minimize\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae latent dimension\n",
    "latent_dim = 1\n",
    "\n",
    "def get_ind(id, df):\n",
    "    return np.where(df['patient_id'] == id)[0]\n",
    "\n",
    "def get_design_matrix(df_effects, fixed_effects_keys, random_effects_keys, r=1, include_interaction=False):\n",
    "    patient_id = df_effects['patient_id'].unique()\n",
    "\n",
    "    X_list = [torch.from_numpy(np.array(df_effects.loc[get_ind(id, df_effects), fixed_effects_keys])).to(torch.float32) for id in patient_id]\n",
    "\n",
    "    if include_interaction==True:\n",
    "        for key in random_effects_keys[1:]:\n",
    "            X_list = [torch.cat((X_i, X_i[:,1:] * torch.from_numpy(np.array(df_effects.loc[get_ind(patient_id[j], df_effects), key])).unsqueeze(-1)\n",
    "                                ), -1).to(torch.float32) for j,X_i in enumerate(X_list)]\n",
    "\n",
    "    X_list = [torch.cat((torch.from_numpy(np.array(df_effects.loc[get_ind(patient_id[j], df_effects), 'age'])).unsqueeze(-1), X_i), -1).to(torch.float32) for j,X_i in enumerate(X_list)]\n",
    "\n",
    "\n",
    "    Z_list = [torch.from_numpy(np.array(df_effects.loc[get_ind(id, df_effects), random_effects_keys])).to(torch.float32) for id in patient_id]\n",
    "    Z_list = [torch.block_diag(*[i for j in range(r)]) for i in Z_list]   \n",
    "    X_list = [torch.block_diag(*[i for j in range(r)]) for i in X_list]\n",
    "    return X_list, Z_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_list, Z_list = get_design_matrix(df_effects, fixed_effects_keys, random_effects_keys, r=latent_dim, include_interaction=False)\n",
    "# pat_ind = np.cumsum([0]+[int(len(X_i)/latent_dim) for X_i in X_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Encoder and Decoder Models and the Mixed Model Parameters. mode='diagonal': Diagonal Covariance Matrix, mode='full': Full Covariance Matrix,\n",
    "def initialize(latent_dim, mode='diagonal'):\n",
    "    encoder = Encoder(\n",
    "        input_dim=np.shape(test_scores_df_encoded)[-1],\n",
    "        hidden_dims=[150], # 2-3 layer\n",
    "        output_dim=latent_dim, \n",
    "        act=torch.nn.Tanh())\n",
    "\n",
    "    decoder = Decoder(\n",
    "        item_positions=np.concatenate([[i]*a for i,a in enumerate(np.array(test_scores_df[test_scores_df.columns[1:]].max(0)).astype(np.int32))]),                            \n",
    "        input_dim=latent_dim,\n",
    "        hidden_dims=[150], \n",
    "        act=torch.nn.Tanh())\n",
    "\n",
    "    var_param = CovarianceMatrix(q*latent_dim, mode=mode)    \n",
    "    return encoder, decoder, var_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_ratio(L_full, L_red):\n",
    "    return 2 * (L_full - L_red)\n",
    "\n",
    "def train_vae(epochs, batch_size, encoder, decoder, optimizer_vae, alpha=1, gamma=1):\n",
    "    steps = int(len(test_scores_df_encoded) / batch_size)\n",
    "    rng = np.random.default_rng(1234)\n",
    "    prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
    "    #progBar = Progress_Bar(epochs, steps, ['nELBO', 'KL', 'Rec Loss', 'Item Error'])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        shuffle = rng.permutation(len(test_scores_df_encoded))\n",
    "        \n",
    "        for step in range(steps):\n",
    "            pat_batch = np.arange(len(test_scores_df_encoded))[shuffle[step*batch_size:(step+1)*batch_size]]\n",
    "\n",
    "            test_data = torch.from_numpy(np.array(test_scores_df_encoded.loc[pat_batch])).to(torch.float32)\n",
    "            test_data_orig = torch.from_numpy(np.array(test_scores_df[test_scores_df.columns[1:]].loc[pat_batch])).to(torch.int32)\n",
    "\n",
    "            optimizer_vae.zero_grad(set_to_none=True)\n",
    "            #encode test scores\n",
    "            mu, log_sig = encoder.encode(test_data)\n",
    "\n",
    "            #reparametrization trick to get latent variables\n",
    "            eps = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
    "            z = mu + log_sig.exp() * eps\n",
    "\n",
    "            #kl divergence\n",
    "            kl = torch.mean(0.5 * torch.sum(mu.square() + torch.exp(2.0 * log_sig) - 1.0 - (2.0 * log_sig), dim=1))\n",
    "\n",
    "            rec_loss, probs = decoder(z, test_data_orig)\n",
    "            nelbo = alpha * kl + gamma * rec_loss\n",
    "\n",
    "            nelbo.backward()\n",
    "            optimizer_vae.step()\n",
    "\n",
    "            #data_pred = torch.stack([torch.argmax(pred, dim=-1) for pred in probs]) \n",
    "            # total test item prediction error  \n",
    "            #item_error = np.mean(np.sum(np.abs(data_pred.detach().numpy() - test_data_orig.T.numpy()), axis=0))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mu, log_sig = encoder.encode(torch.from_numpy(np.array(test_scores_df_encoded)).to(torch.float32))\n",
    "        epsilon = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
    "\n",
    "        z = mu + log_sig.exp() * epsilon\n",
    "        return z.detach()\n",
    "\n",
    "\n",
    "def calc_likelihood(var_param, Z_list, X_list, z_list):\n",
    "    Phi, sigma = var_param()\n",
    "    N = sum([len(Z_i) for Z_i in Z_list])\n",
    "\n",
    "    V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list]\n",
    "    #epsilon = 1e-5  # Regularisierungswert\n",
    "    #V_inv_list = [(V_i + epsilon * torch.eye(V_i.size(0))).inverse() for V_i in V_list]\n",
    "    V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "    \n",
    "    Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list, V_inv_list)]).sum(dim=0)\n",
    "    Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "    #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
    "    \n",
    "    EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "    #EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_batch, Z_list_batch, V_inv_list, z_list)]\n",
    "\n",
    "    residual_list = [y_i - X_i @ EBLUE for y_i, X_i in zip(z_list, X_list)]\n",
    "    #Mixed model prediction\n",
    "    #z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_batch, Z_list_batch, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "\n",
    "    log_det_V = torch.stack([V_i.det().clamp(min=1e-12).log() for V_i in V_list]).sum()\n",
    "    const = torch.log(torch.tensor(2.0 * torch.pi))\n",
    "    rt_V_inv_r = torch.stack([r_i.t() @ V_i_inv @ r_i for r_i, V_i_inv in zip(residual_list, V_inv_list)]).sum()\n",
    "\n",
    "        #negative mixed models likelihood\n",
    "    nML = 0.5 * (log_det_V + rt_V_inv_r + N * const) #/ N   \n",
    "         \n",
    "    return nML \n",
    "\n",
    "\n",
    "def train_vae_2(epochs, batch_size, encoder, decoder, optimizer_vae, Z_list, X_list, z_list_f, var_param, alpha=1, gamma=1, eta=1, beta=1):\n",
    "    steps = int(num_patients / batch_size)\n",
    "    rng = np.random.default_rng(1234)\n",
    "    prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        shuffle = rng.permutation(num_patients)\n",
    "        \n",
    "        for step in range(steps):\n",
    "            #draw minibatch\n",
    "            pat_batch = patients[shuffle[step*batch_size:(step+1)*batch_size]]\n",
    "            pat_ind_batch = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in pat_batch]\n",
    "            \n",
    "            ind_batch = []\n",
    "            add = 0\n",
    "            for ind in range(len(pat_ind_batch)):\n",
    "                len_i = len(pat_ind_batch[ind])\n",
    "                ind_batch += [torch.arange(add, add + len_i)]\n",
    "                add += len_i\n",
    "\n",
    "            Z_list_batch = [Z_list[pat] for pat in pat_batch]\n",
    "            X_list_batch = [X_list[pat] for pat in pat_batch]\n",
    "            \n",
    "            test_data = torch.concatenate([torch.from_numpy(np.array(test_scores_df_encoded.loc[ind])).to(torch.float32) for ind in pat_ind_batch])\n",
    "            test_data_orig = torch.concatenate([torch.from_numpy(np.array(test_scores_df[test_scores_df.columns[1:]].loc[ind])).to(torch.int32) for ind in pat_ind_batch])\n",
    "            \n",
    "            optimizer_vae.zero_grad(set_to_none=True)\n",
    "            #encode test scores\n",
    "            mu, log_sig = encoder.encode(test_data)\n",
    "\n",
    "            #reparametrization trick to get latent variables\n",
    "            eps = prior.sample(torch.Size([log_sig.size(dim=0)]))\n",
    "            z = mu + log_sig.exp() * eps\n",
    "            \n",
    "            #kl divergence\n",
    "            kl = torch.mean(0.5 * torch.sum(mu.square() + torch.exp(2.0 * log_sig) - 1.0 - (2.0 * log_sig), dim=1))\n",
    "\n",
    "            # get the response variable list (latent z)\n",
    "            z_list = [z[ind].flatten().to(torch.float32) for ind in ind_batch]\n",
    "\n",
    "            #Mixed model loglikelihood loss. Notation follows https://www.sfu.ca/sasdoc/sashtml/stat/chap41/sect23.htm\n",
    "            Phi, sigma = var_param()\n",
    "\n",
    "            V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list_batch]\n",
    "            V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "            \n",
    "            Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list_batch, V_inv_list)]).sum(dim=0)\n",
    "            Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list_batch, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "            #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
    "            if torch.abs(torch.det(Xt_V_inv_X)) > 1e-6:\n",
    "                EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "                EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_batch, Z_list_batch, V_inv_list, z_list)]\n",
    "        \n",
    "                #Mixed model prediction\n",
    "                z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_batch, Z_list_batch, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "\n",
    "\n",
    "                #distance between encoder latent variables and mixed model prediction\n",
    "                residuals = ((z_pred - z) ** 2).sum(1).mean()\n",
    "\n",
    "                # calculate the nML\n",
    "                # Phi, sigma = var_param()\n",
    "                # N = sum([len(Z_i) for Z_i in Z_list])\n",
    "                # V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list]\n",
    "                # V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "                # Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list, V_inv_list)]).sum(dim=0)\n",
    "                # Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list, V_inv_list, z_list_f)]).sum(dim=0)\n",
    "                # EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "                # residual_list = [y_i - X_i @ EBLUE for y_i, X_i in zip(z_list_f, X_list)]\n",
    "                # log_det_V = torch.stack([V_i.det().clamp(min=1e-12).log() for V_i in V_list]).sum()\n",
    "                # const = torch.log(torch.tensor(2.0 * torch.pi))\n",
    "                # rt_V_inv_r = torch.stack([r_i.t() @ V_i_inv @ r_i for r_i, V_i_inv in zip(residual_list, V_inv_list)]).sum()\n",
    "                # nML = 0.5 * (log_det_V + rt_V_inv_r + N * const) #/ N\n",
    "                nML = calc_likelihood(var_param, Z_list, X_list, z_list_f)\n",
    "\n",
    "                #reconstruction loss\n",
    "                rec_loss, probs = decoder(z_pred, test_data_orig)\n",
    "\n",
    "                #loss function\n",
    "                nelbo = alpha * kl + eta * residuals + gamma * rec_loss + beta * nML\n",
    "                \n",
    "                nelbo.backward()\n",
    "                optimizer_vae.step()    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mu, log_sig = encoder.encode(torch.from_numpy(np.array(test_scores_df_encoded)).to(torch.float32))\n",
    "        epsilon = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
    "\n",
    "        z = mu + log_sig.exp() * epsilon\n",
    "        return z.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\n",
      " LRT Value: -1.05615234375\n",
      "Epoch: 1\n",
      "\n",
      " LRT Value: -0.0361328125\n"
     ]
    }
   ],
   "source": [
    "num_simulations = 1000\n",
    "iterations = 30\n",
    "lrt_results = []\n",
    "\n",
    "all_epochs_dict = {} #dictionary to save all models\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_parameters')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "fixed_effects_keys_full = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never', 'sex']\n",
    "random_effects_keys_full = ['intercept', 'since_medication', 'since_switch']\n",
    "# reduced model without fixed effect 'sex' \n",
    "fixed_effects_keys_red = ['family_affected', 'sco_surg', '≤3', 'onset_age', 'presym_diag', 'presymptomatic', 'stand_lost', 'stand_gained', 'stand_never']\n",
    "random_effects_keys_red = ['intercept', 'since_medication', 'since_switch']\n",
    "q = len(random_effects_keys_full)\n",
    "\n",
    "for i in range(num_simulations): \n",
    "    print(f\"Epoch: {i}\")\n",
    "    #prepare dataset\n",
    "    test_scores_df = pd.read_csv(os.getcwd()+'/test_scores.csv')\n",
    "    test_scores_df_encoded = thermometer_encode_df(test_scores_df, test_scores_df.columns[1:])\n",
    "    time_df = pd.read_csv(os.getcwd()+'/time_df.csv')\n",
    "    time_df['intercept'] = np.ones(time_df.shape[0])\n",
    "    baseline_df = pd.read_csv(os.getcwd()+'/baseline_df.csv')\n",
    "    baseline_df['sex'] = np.random.randint(2, size=baseline_df.shape[0])\n",
    "    df_effects = pd.merge(baseline_df, time_df, on='patient_id', how='inner')\n",
    "\n",
    "    patients = torch.from_numpy(np.array(baseline_df['patient_id']))\n",
    "    num_patients = len(patients)\n",
    "\n",
    "    X_list_full, Z_list_full = get_design_matrix(df_effects, fixed_effects_keys_full, random_effects_keys_full, r=latent_dim)\n",
    "    X_list_red, Z_list_red = get_design_matrix(df_effects, fixed_effects_keys_red, random_effects_keys_red, r=latent_dim)   \n",
    "    \n",
    "    pat_ind = np.cumsum([0]+[int(len(X_i)/latent_dim) for X_i in X_list_full])\n",
    "\n",
    "    encoder, decoder = initialize(latent_dim)[0:2]\n",
    "    optimizer_vae = torch.optim.Adam([ \n",
    "        {'params': encoder.parameters(), 'lr': 0.01},  \n",
    "        {'params': decoder.parameters(), 'lr': 0.01},  \n",
    "    ])  \n",
    "    z = train_vae(2, 128, encoder, decoder, optimizer_vae)\n",
    "    pat_ind_b = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in patients]\n",
    "\n",
    "    for j in range(iterations):\n",
    "        # print(f\"Iteration: {j}\")\n",
    "        if j != 0:\n",
    "            calc_likelihood(var_param_full, Z_list_full, X_list_full, z_list)\n",
    "            z = train_vae_2(1, 128, encoder, decoder, optimizer_vae, Z_list_full, X_list_full, z_list, var_param_full, alpha=1, gamma=1, eta=10, beta = 10)\n",
    "        \n",
    "        z_list = [z[ind].flatten().to(torch.float32) for ind in pat_ind_b]\n",
    "        \n",
    "        var_param_full = CovarianceMatrix(q*latent_dim, mode='diagonal')  \n",
    "\n",
    "        optimizer_mm_full = torch.optim.LBFGS([ \n",
    "            {'params': var_param_full.parameters(),\n",
    "            'lr': 0.25, \n",
    "            'max_iter':200, \n",
    "            'max_eval': 500, \n",
    "            'tolerance_grad':1e-09, \n",
    "            'tolerance_change':1e-11, \n",
    "            'history_size':200}\n",
    "        ])\n",
    "        \n",
    "        def closure():\n",
    "            optimizer_mm_full.zero_grad()\n",
    "            res = calc_likelihood(var_param_full, Z_list_full, X_list_full, z_list)\n",
    "            res.backward()\n",
    "            return res\n",
    "        \n",
    "        optimizer_mm_full.step(closure) \n",
    "\n",
    "    var_param_red = CovarianceMatrix(q*latent_dim, mode='diagonal') \n",
    "    optimizer_mm_red = torch.optim.LBFGS([ \n",
    "        {'params': var_param_red.parameters(),\n",
    "        'lr': 0.25, \n",
    "        'max_iter':200, \n",
    "        'max_eval': 500, \n",
    "        'tolerance_grad':1e-09, \n",
    "        'tolerance_change':1e-11, \n",
    "        'history_size':200}\n",
    "    ])\n",
    "\n",
    "    def closure_red():\n",
    "        optimizer_mm_red.zero_grad()\n",
    "        res = calc_likelihood(var_param_red, Z_list_red, X_list_red, z_list)\n",
    "        res.backward()\n",
    "        return res\n",
    "        \n",
    "    optimizer_mm_red.step(closure_red)\n",
    "    \n",
    "    res_full = calc_likelihood(var_param_full, Z_list_full, X_list_full, z_list)\n",
    "    res_red = calc_likelihood(var_param_red, Z_list_red, X_list_red, z_list)\n",
    "    \n",
    "    lrt_val = likelihood_ratio(res_full, res_red).detach()\n",
    "    lrt_results.append(lrt_val)\n",
    "\n",
    "    print(f\"\\n LRT Value: {lrt_val}\")\n",
    "\n",
    "    all_epochs_dict[f'epoch_{i}'] = {\n",
    "        'encoder_state_dict': encoder.state_dict(),\n",
    "        'decoder_state_dict': decoder.state_dict(),\n",
    "        'var_param_full': var_param_full,\n",
    "        'optimizer_vae_state_dict': optimizer_vae.state_dict(),\n",
    "        'var_param_red': var_param_red,\n",
    "        'optimizer_mm_full': optimizer_mm_full,\n",
    "        'optimizer_mm_red': optimizer_mm_red,\n",
    "        'X_list_full' : X_list_full,\n",
    "        'Z_list_full' : Z_list_full,\n",
    "        'X_list_red' : X_list_red,\n",
    "        'Z_list_red' : Z_list_red,\n",
    "        'z_list': z_list,\n",
    "        'lrt_val': lrt_val\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "torch.save(lrt_results, os.path.join(save_dir, 'params_nML_in_lossfkt.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the histogr<am of the LRT-statistic\n",
    "plt.hist(lrt_results, bins=50, density=True, alpha=0.6, color='g', label='Histogramm der LRT-Statistik')\n",
    "\n",
    "# Chi-Quadrat-Verteilung mit zwei Freiheitsgraden plotten (für Vergleich)\n",
    "x = np.linspace(0, max(lrt_results), 100)\n",
    "plt.plot(-x, chi2.pdf(x, 1), 'r-', lw=1, label='Chi-Square distribution (df=1)')\n",
    "\n",
    "\n",
    "# Beschriftungen hinzufügen\n",
    "plt.title('Histogramm der Likelihood-Ratio-Teststatistiken')\n",
    "plt.xlabel('Teststatistik')\n",
    "plt.ylabel('Häufigkeit')\n",
    "plt.legend()\n",
    "\n",
    "# Save the histogram in the current directory\n",
    "histogram_path = os.path.join(os.getcwd(), 'hist_nML_in_lossfkt.png')\n",
    "plt.savefig(histogram_path)\n",
    "\n",
    "# Histogramm anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_vae(300, 60,X_list, Z_list, encoder, decoder, var_param, optimizer_vae, alpha=1, gamma=1, delta=1, eta=1)  \n",
    "# get the model prediction:\n",
    "# def eval_vae(X_list, Z_list, var_param, encoder):\n",
    "#     with torch.no_grad():\n",
    "#         pat_ind_batch = [torch.arange(pat_ind[i],pat_ind[i+1]) for i in patients]\n",
    "#         prior = Normal(torch.zeros(torch.Size([latent_dim])), torch.ones(torch.Size([latent_dim])))\n",
    "\n",
    "#         test_data = torch.concatenate([torch.from_numpy(np.array(test_scores_df_encoded.loc[ind])).to(torch.float32) for ind in pat_ind_batch])\n",
    "\n",
    "#         mu, log_sig = encoder.encode(test_data)\n",
    "\n",
    "#         eps = prior.sample(torch.Size([log_sig.size(dim=0)])) \n",
    "#         z = mu + log_sig.exp() * eps # latent data\n",
    "\n",
    "#         z_list = [z[ind].flatten().to(torch.float32) for ind in pat_ind_batch]\n",
    "\n",
    "#         Phi, sigma = var_param()\n",
    "#         N = sum([len(Z_i) for Z_i in Z_list])\n",
    "\n",
    "#         V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list]\n",
    "#         V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "        \n",
    "#         Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list, V_inv_list)]).sum(dim=0)\n",
    "#         Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "#         EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "#         EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list, Z_list, V_inv_list, z_list)]\n",
    "\n",
    "#         residual_list = [y_i - X_i @ EBLUE for y_i, X_i in zip(z_list, X_list)]\n",
    "#         z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list, Z_list, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "\n",
    "#         log_det_V = torch.stack([V_i.det().clamp(min=1e-12).log() for V_i in V_list]).sum()\n",
    "#         const = torch.log(torch.tensor(2.0 * torch.pi))\n",
    "#         rt_V_inv_r = torch.stack([r_i.t() @ V_i_inv @ r_i for r_i, V_i_inv in zip(residual_list, V_inv_list)]).sum()\n",
    "\n",
    "#         nML = 0.5 * (log_det_V + rt_V_inv_r + N * const) \n",
    "#         return mu, z, z_pred, nML\n",
    "\n",
    "# def calc_likelihood_full_model(var_param, Z_list_full, X_list_full, z_list):\n",
    "#     if isinstance(var_param, CovarianceMatrix):\n",
    "#         Phi, sigma = var_param.forward()  # Verwenden Sie die forward-Methode korrekt\n",
    "#     else:\n",
    "#         raise TypeError(\"var_param must be an instance of CovarianceMatrix\")\n",
    "\n",
    "#     N = sum([len(Z_i) for Z_i in Z_list_full])\n",
    "#     V_list = [Z_i @ Phi @ Z_i.t() + torch.eye(Z_i.size(0)) * sigma for Z_i in Z_list_full]\n",
    "#     V_inv_list = [V_i.inverse() for V_i in V_list]\n",
    "            \n",
    "#     Xt_V_inv_X = torch.stack([X_i.t() @ V_i_inv @ X_i for X_i, V_i_inv in zip(X_list_full, V_inv_list)]).sum(dim=0)\n",
    "#     Xt_V_inv_y = torch.stack([X_i.t() @ V_i_inv @ y_i for X_i, V_i_inv, y_i in zip(X_list_full, V_inv_list, z_list)]).sum(dim=0)\n",
    "\n",
    "#     #Check if Xt_V_inv_X is invertible. Only needed for mini batching\n",
    "#     if torch.abs(torch.det(Xt_V_inv_X)) > 1e-6:\n",
    "#         EBLUE = Xt_V_inv_X.inverse() @ Xt_V_inv_y\n",
    "#         EBLUP_list = [Phi @ Z_i.t() @ V_i_inv @ (y_i - X_i @ EBLUE) for X_i, Z_i, V_i_inv, y_i in zip(X_list_full, Z_list_full, V_inv_list, z_list)]\n",
    "\n",
    "#         #Mixed model prediction\n",
    "#         z_pred = torch.cat([X_i @ EBLUE + Z_i @ EBLUP_i for X_i, Z_i, EBLUP_i in zip(X_list_full, Z_list_full, EBLUP_list)]).reshape((-1, latent_dim))\n",
    "         \n",
    "#     return z_pred\n",
    "\n",
    "\n",
    "# def optimize_mixed_model(closure, params):\n",
    "#     # Stellen Sie sicher, dass params in einen Tensor umgewandelt werden können\n",
    "#     if isinstance(params, CovarianceMatrix):\n",
    "#         x0 = params.L_param\n",
    "#     else:\n",
    "#         x0 = torch.as_tensor(params)\n",
    "    \n",
    "#     result = minimize(closure, x0, method='bfgs', max_iter=6)\n",
    "#     return result\n",
    "\n",
    "    # optimizer_mm_full = optim.LBFGS(var_param_full.parameters(), lr=1.0)\n",
    "    # optimizer_mm_red = optim.LBFGS(var_param_red.parameters(), lr=1.0)\n",
    "    #ohne batches\n",
    "    #res = minimize(calc_likelihood_full, var_param_full.parameters(), method='bfgs', max_iter=6)\n",
    "\n",
    "\n",
    "    # def closure():\n",
    "    #     optimizer_mm_full.zero_grad()\n",
    "    #     res = calc_likelihood_full(var_param_full)\n",
    "    #     res.backward()\n",
    "    #     return res\n",
    "        \n",
    "    # optimizer_mm_full.step(closure)\n",
    "\n",
    "    # res_full = minimize(calc_likelihood_full, var_param_full.parameters(), method='bfgs', max_iter=6)\n",
    "    # res_red = minimize(calc_likelihood_red, var_param_red.parameters(), method='bfgs', max_iter=6)\n",
    "\n",
    "    # steps = 300\n",
    "    # print('\\nTrain full:')\n",
    "    # for j in range(steps):\n",
    "    #     optimizer_mm_full.zero_grad(set_to_none=True)\n",
    "    #     res_full = calc_likelihood_full(var_param_full)\n",
    "    #     res_full.backward()\n",
    "    #     optimizer_mm_full.step()\n",
    "\n",
    "    # print('\\nTrain reduced:')\n",
    "    # for k in range(steps):\n",
    "    #     optimizer_mm_red.zero_grad(set_to_none=True)\n",
    "    #     res_red = calc_likelihood_red(var_param_red)\n",
    "    #     res_red.backward()\n",
    "    #     optimizer_mm_red.step() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
